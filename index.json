
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    
      
      
      
    [{"authors":null,"categories":[""],"content":" makefile 很早就想写了，高阶概念总是忘了又忘，一千个人一千个哈姆雷特，理解抽象概念的方式各有不同\nWhat’s makefile? ","date":1697500800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1697500800,"objectID":"4c6c7d416cbf8fabd4172b47b87f18ea","permalink":"https://domyson.github.io/post/makefile/","publishdate":"2023-10-17T00:00:00Z","relpermalink":"/post/makefile/","section":"post","summary":" makefile 很早就想写了，高阶概念总是忘了又忘，一千个人一千个哈姆雷特，理解抽象概念的方式各有不同\nWhat’s makefile?","tags":[""],"title":"makefile","type":"post"},{"authors":null,"categories":["typelang"],"content":"序 还没写\n","date":1696377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696377600,"objectID":"e7553450e004e93e72c94076c6b8fb6e","permalink":"https://domyson.github.io/post/typelang/3/","publishdate":"2023-10-04T00:00:00Z","relpermalink":"/post/typelang/3/","section":"post","summary":"序 还没写\n","tags":[""],"title":"AST 抽象语法树","type":"post"},{"authors":null,"categories":["typelang"],"content":"序 还没写\n","date":1696377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696377600,"objectID":"87d6b8e03529135abea2ed62fdc875fd","permalink":"https://domyson.github.io/post/typelang/5/","publishdate":"2023-10-04T00:00:00Z","relpermalink":"/post/typelang/5/","section":"post","summary":"序 还没写\n","tags":[""],"title":"Bytecode","type":"post"},{"authors":null,"categories":["typelang"],"content":"序 还没写\n","date":1696377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696377600,"objectID":"2ad2ee1825b9b579158e95a2874c1535","permalink":"https://domyson.github.io/post/typelang/2/","publishdate":"2023-10-04T00:00:00Z","relpermalink":"/post/typelang/2/","section":"post","summary":"序 还没写\n","tags":[""],"title":"grammer","type":"post"},{"authors":null,"categories":["typelang"],"content":"序 对于一个源码文件而言，里面的内容只是一个个字符，机器是无法识别的，而词法分析器的作用类似于转义器，将一个个字符拆成若干个有特定意义的词，而这一过程称为词法分析，此时它也不能被机器(或者这个虚拟机)识别\n词法分析器 Token,Keyword,界符，常数，运算符 token 以及 keyword是存在区别的，像token 可以是认为是一个此的描述，如:\nconst int sum = 100; typedef struct my_struct{ int a ; unsigned int b; char *c; }; 学过语言的都知道，什么是语言关键字。\ntypedef,struct,int,my_struct 等都可以认为是一个token,可以简单理解为一个词的代号，而keyword属于被包含关系，typedef,struct,int 它们属于keyword,因为它们是程序内部定义\u0026#34;词\u0026#34;，而my_struct则属于用于定义的，\n像类似于 +,-,*,/ 等都属于运算符\n其中 const int sum = 100; 中的100 则认为是一个常数.\n基本设计 首先我们为一个词定义一些token,如 typedef enum Token { EOF = 0, COMMENT, IDENT, __KEYWORD_BEGIN IF, ELSE, SWITCH, CASE, RETURN, // etc... __KEYWORD_END, __MATH_BEGIN Add, // + Sub, // - Mul, // * Quo, // / Rem, // % And, // \u0026amp; Or, // | __MATH_END }; 可以属于到几个特殊的定义 __XXX_BEING,__XXX_END 这是为了方便后续快速区分这些\u0026#34;词\u0026#34;是属于那些种类\n其次我们需要定义一个辅助函数，如上所述 const int sum = 100; 而这100解析出来应该是个数字而不是一个字符串\nbool is_dight(char c){ return \u0026#39;0\u0026#39;\u0026lt;=c \u0026amp;\u0026amp; c \u0026lt;=\u0026#39;9\u0026#39;; } 这一步只处理了一个字符，而后续只需要一直扫描直到不能满足条件为止，如出现一个字母，那么可以认为语法错误，扫描到;则认为是结束了\nbool is_letter(char c) { return (\u0026#39;a\u0026#39; \u0026lt;=c \u0026amp;\u0026amp; c \u0026lt;=\u0026#39;z\u0026#39;) || (\u0026#39;A\u0026#39; \u0026lt;=c \u0026amp;\u0026amp; c \u0026lt;=\u0026#39;Z\u0026#39;); } 这个函数专门处理一些关键字，和identity\n辅助函数只能处理当前字符，那么如何知道是否满足某个条件，如变量只允许下划线和字母开头，答案就是状态机，类似于一个临时缓冲，将扫描到的字符放入其中方便做检测，而实际开发中其实只需要记录两次偏移的位置就可以拿到这段字符了\n分析器的分析流程 分析器其实就是按照一个个遍历的方式将这串文本拆成一个个的token的过程\ntypedef struct lex { unsigned int size; // sizeof the buf length unsigned int offset; // current read offset unsigned int line; char *buf; }; typedef struct token{ Token __token; unsigned int line; }; int lex_next(lex *l,token *tk){ while(l-\u0026gt;offset \u0026lt; l -\u0026gt;size){ // lex_skipwhitespace() switch (l-\u0026gt;buf[l-\u0026gt;offset]){ case \u0026#39;/\u0026#39;: if (l-\u0026gt;buf[l-\u0026gt;offset +1] == \u0026#39;/\u0026#39;){ // lex_skipcomment() tk-\u0026gt;__token = COMMENT; }else{ // maybe is math div } break // etc ... switch } } } 至此，词法分析器的大致原理已经分析完毕了，后续可以参考 AST 以及 语法分析器Grammar\n优化 emmm… 本身而言这个可以段可以不写，如果你能看到这，你可以接触更高阶的知识。作为一个由追求的程序员，优化是必须的，去tm的后续优化，哥写代码就是要一边写一边优化 :)\nI/O 读取优化 通常而言，对于不大的文件，我们直接读取全部内容到内存中，然后进行处理，但是这样会存在一个问题，就是如果文件过大，那么内存会爆，所以需要进行优化，将文件内容分段读取，然后进行处理，这样可以避免一次性读取过多内容，从而避免内存溢出，以及过多的内存碎片。 如上述改为lex结构改为固定缓冲，如 char buf[512] 并增加一个offset偏移量和文件编译指针，对于后续其它文件而言都可以复用这个结构。\n扫描优化 机器不同于人脑，人脑可以可以同时处理多个字符输入，但对于计算机而言，只能一个一个处理，我们可以定义一些非二义性的关键字和词组，如\\\\ 我们可以立刻判断这是注释，直接 goto 到对应的 label,而不是逐个字符判断。直接人为处理\n伪共享优化 CPU在读取数据时，是以一个缓存行为单位读取的（64byte），假设这个缓存行中有两个long类型的变量a、b，当一个线程A读取a，并修改a，线程A在未写回缓存之前，另一个线程B读取了b，读取的这个b所在的缓存是无效的（前面说的缓存失效），本来是为了提高性能是使用的缓存，现在为了提高命中率，反而被拖慢了，这就是传说中的伪共享。最简单的方式就是以一个缓存行为单位读取，这样就不会存在伪共享问题了。从上述可知 sizeof(lex)== 24 我们只需要填充 char byte[40] 让它一次能填满缓冲行即可。\n更多的可以查看 MESI协议\n上述优化完毕的测试结果，对于以下脚本仅需 1.216ns\n// this is a comment int32 a // this is back comment int32 b=33 float32 c = 3.14 int32 a1 = 0b0101 int32 a2 = 0x123456789abcdef int32 a3 = 012323 bool d = false bool c = true function fib(int32 n) int32 { if (n \u0026lt; 2){ return n } return fib(n-1) + fib(n-2) } fib(b) ","date":1696377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696377600,"objectID":"79981793cffddf591564ea27a6aaa7dd","permalink":"https://domyson.github.io/post/typelang/1/","publishdate":"2023-10-04T00:00:00Z","relpermalink":"/post/typelang/1/","section":"post","summary":"序 对于一个源码文件而言，里面的内容只是一个个字符，机器是无法识别的，而词法分析器的作用类似于转义器，将一个个字符拆成若干个有特定意义的词，而这一过程称为词法分析，此时它也不能被机器(或者这个虚拟机)识别\n","tags":[""],"title":"lex","type":"post"},{"authors":null,"categories":["typelang"],"content":"序 还没写\n","date":1696377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696377600,"objectID":"ab3217a504455b983de66d1435042805","permalink":"https://domyson.github.io/post/typelang/4/","publishdate":"2023-10-04T00:00:00Z","relpermalink":"/post/typelang/4/","section":"post","summary":"序 还没写\n","tags":[""],"title":"Register","type":"post"},{"authors":null,"categories":["typelang"],"content":" 这篇文章将会是一个系列，更新会比源码慢，文档写的也不会写的很完全，名字暂定 typelang, C syntax-like\n设计缘由 早在2019之前就想开发一门脚本语言，一是加深编译原理的理解，二是觉得程序员不应该消耗在语言特性上，也一直想为自己的服务端框架 skynet-x 写一门dsl，现在是用lua作为服务的脚本端。但由于的若约束性导致在开发的时候很多同时并不够优雅，总是以一种奇怪的方式来解决问题，Lua本身并没有任何问题，它被设计之初是为了修补C的不足，但它的语法设计却并不符合我的预期。\n尽管它的性能是脚本语言中顶尖的，但是一些隐式写法并不能保证它的预期性能，如混合table,过多的函数调用栈，字符串操作以及无类型系统。\n关于类型系统有利有弊，但我个人的观点是宁愿多出30%的开发时间，从而减少70%的bug。\nRegister Based 和 Stack Based 如python,ruby,js,java 属于 Stack Based, 而lua在5.0之后则属于Register Based.\n关于它们的区别，无非是一次表达式计算需要多少步骤，形如 c=a+b，对于stack base，需要3个步骤，而对于register base，只需要1个步骤。\n目标 C syntax-like\n强类型，消除弱类型的副作用，编译时进行类型检查\n提供协程支持，最开始的想法是类似于 v8-vm,但后续有了新的想法，为了方便集成宿主语言的异步操作，内置yield 关键字。\n支持宿主语言交互\n函数式\n模式匹配\nregister based\njit编译，暂时考虑 llvm\n目录 词法分析器(Lexer)\n语法分析器(Grammar)\n抽象语法树(AST)\nRegisterBased\n","date":1696377600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1696377600,"objectID":"f488ec6768ea31a9e5336981324b3ebe","permalink":"https://domyson.github.io/post/typelang/0/","publishdate":"2023-10-04T00:00:00Z","relpermalink":"/post/typelang/0/","section":"post","summary":" 这篇文章将会是一个系列，更新会比源码慢，文档写的也不会写的很完全，名字暂定 typelang, C syntax-like\n设计缘由 早在2019之前就想开发一门脚本语言，一是加深编译原理的理解，二是觉得程序员不应该消耗在语言特性上，也一直想为自己的服务端框架 skynet-x 写一门dsl，现在是用lua作为服务的脚本端。但由于的若约束性导致在开发的时候很多同时并不够优雅，总是以一种奇怪的方式来解决问题，Lua本身并没有任何问题，它被设计之初是为了修补C的不足，但它的语法设计却并不符合我的预期。\n尽管它的性能是脚本语言中顶尖的，但是一些隐式写法并不能保证它的预期性能，如混合table,过多的函数调用栈，字符串操作以及无类型系统。\n关于类型系统有利有弊，但我个人的观点是宁愿多出30%的开发时间，从而减少70%的bug。\n","tags":[""],"title":"typelang","type":"post"},{"authors":null,"categories":["Zen"],"content":"简介 DatatableModule 是一个基于 kpb 编码的配置文件管理系统,它定义了一个配置文件的数据结构，并提供了相应的API来操作和访问配置文件。在Zen中它是一个GameComponent。它包含了一个代码生成器，和数据解析器和编码器。\n数据表的加载只有4(2)个接口 LoadDatatable\u0026lt;T\u0026gt;(bool lazy) GetRow\u0026lt;T\u0026gt;(int row) 以及一套同作用的异步接口，前者获取一整张表，后者获取某表的某一行数据，即对应的数据结构体。\nDatatable 静默行为是 Lazy load 对于同一张数据表，它只会根据需要读取指定行然后才缓存，而不是一次性读取所有表格。\nFeature lazy load,它不会加载表格的所有数据，而是按照需要动态一部分一部分的加载，直到全部加载完毕。\nDatatableModule 加载接口提供同步和异步两种模式，也可以加载远程资源，依赖于 Resource\nDatatableModule 提供代码和数据生成的编辑器，无需关注实现逻辑。\n多种类型数据支持 bool,int,float,string,binary,int*,float*,string*,满足绝大部分场景 （2024/05/23）增加了定长数据的支持，减少内存消耗。\n基于kproto编码协议，极小的二进制文件，以及极快的编解码速度。\n栈内存映射，大部分情况下不需要开辟堆空间，节省一部分堆内存的分配，减少Mono Reserved的分配。\n","date":1680307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680307200,"objectID":"f49e3b6ffd1b90a8eeb7770ab23fe025","permalink":"https://domyson.github.io/post/zen/3/","publishdate":"2023-04-01T00:00:00Z","relpermalink":"/post/zen/3/","section":"post","summary":"简介 DatatableModule 是一个基于 kpb 编码的配置文件管理系统,它定义了一个配置文件的数据结构，并提供了相应的API来操作和访问配置文件。在Zen中它是一个GameComponent。它包含了一个代码生成器，和数据解析器和编码器。\n数据表的加载只有4(2)个接口 LoadDatatable\u003cT\u003e(bool lazy) GetRow\u003cT\u003e(int row) 以及一套同作用的异步接口，前者获取一整张表，后者获取某表的某一行数据，即对应的数据结构体。\nDatatable 静默行为是 Lazy load 对于同一张数据表，它只会根据需要读取指定行然后才缓存，而不是一次性读取所有表格。\nFeature lazy load,它不会加载表格的所有数据，而是按照需要动态一部分一部分的加载，直到全部加载完毕。\nDatatableModule 加载接口提供同步和异步两种模式，也可以加载远程资源，依赖于 Resource\nDatatableModule 提供代码和数据生成的编辑器，无需关注实现逻辑。\n多种类型数据支持 bool,int,float,string,binary,int*,float*,string*,满足绝大部分场景 （2024/05/23）增加了定长数据的支持，减少内存消耗。\n基于kproto编码协议，极小的二进制文件，以及极快的编解码速度。\n栈内存映射，大部分情况下不需要开辟堆空间，节省一部分堆内存的分配，减少Mono Reserved的分配。\n","tags":[""],"title":"datatable","type":"post"},{"authors":null,"categories":["Zen"],"content":"EntityManager是一个很重要的模块，像游戏开发本身就是视觉感知，而EntityManager是对所有场景物体的统一抽象封装, 并提供一系列通用操作，EntityManager 本身是一个抽象类，提供了一定程度的通用性操作，但针对一些特殊情况我们还是需要针对特定问题特定实现（千万不想要想着做平，来自某家公司的教训:)）\nEntityManager 附带一个默认的 EntityController,提供一些常规的实体控制，像 Zen的UI框架就是基于 EntityManager的一个具体实现。\nEntity 抽象描述一个物体的实体，它的生命周期函数定义类似于GameComponent,但是它的调度不由GameEntry而是 GameComponent。\n简单来说，要创建一个物体首先我们需要定义它的逻辑模板（骨架）以及它的数据（描述）\n举个例子\npublic struct EnemyData:IEntityData{ // 对于实体数据接口，资源名必不可少 public string Assets {get;set;} public void OnCtor(){ // 有些时候，实体的数据更关卡等级或这地图这类外部数据挂钩，可能需要在这里动态设置一次 } } // 定义Entity的逻辑模板 public struct Enemy:Entity { protected EnemyData userdata; protected void OnCtor(){ // init setup... } protected void OnUpdate(float delta,float unscaleDelta){ // loop logic. } } void dosomething(){ // 直接在默认的EntityManager中创建一个实体 GameEntry.GetComponent\u0026lt;EntityManager\u0026gt;().Load\u0026lt;Enemy\u0026gt;(new EnemyData()); } 对于实体的销毁，像敌人死亡，特效消失之类的，仅仅只需要设置一个 Alive 属性，即可完成，生命周期由EntityManger自行决断。\n需要注意的是 继承IEntityData的数据模板是会一直复用的，它与 Entity的复用规则不同，后者复用的是Entity所持有的实体，因为它本身只是一系列函数集合且很少会带有数据并不会占用太多的内存，而前者大部分情况下是都是通过读表获取，复杂的实体数据可能会导致内存异常大，所以保留实体数据是EntityManager的默认行为。\nEntitySettings EntityManager可能需要在某些大量对象时使用对象池（Entity），或者内存池(EntityData),但在大多数情况下，框架并不清楚是否需要对象池，或者是需要一个定长周期的物体（子弹或者特效）。\n这个时候需要设置就非常有必要了，可以决断出是否需要且生命周期（keepalive）或者是需要多大的对象池，以及自动孵化的频率了。\n","date":1680307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680307200,"objectID":"dbd1e931315490dea42c6cb32cae6006","permalink":"https://domyson.github.io/post/zen/5/","publishdate":"2023-04-01T00:00:00Z","relpermalink":"/post/zen/5/","section":"post","summary":"EntityManager是一个很重要的模块，像游戏开发本身就是视觉感知，而EntityManager是对所有场景物体的统一抽象封装, 并提供一系列通用操作，EntityManager 本身是一个抽象类，提供了一定程度的通用性操作，但针对一些特殊情况我们还是需要针对特定问题特定实现（千万不想要想着做平，来自某家公司的教训:)）\nEntityManager 附带一个默认的 EntityController,提供一些常规的实体控制，像 Zen的UI框架就是基于 EntityManager的一个具体实现。\nEntity 抽象描述一个物体的实体，它的生命周期函数定义类似于GameComponent,但是它的调度不由GameEntry而是 GameComponent。\n简单来说，要创建一个物体首先我们需要定义它的逻辑模板（骨架）以及它的数据（描述）\n举个例子\npublic struct EnemyData:IEntityData{ // 对于实体数据接口，资源名必不可少 public string Assets {get;set;} public void OnCtor(){ // 有些时候，实体的数据更关卡等级或这地图这类外部数据挂钩，可能需要在这里动态设置一次 } } // 定义Entity的逻辑模板 public struct Enemy:Entity { protected EnemyData userdata; protected void OnCtor(){ // init setup... } protected void OnUpdate(float delta,float unscaleDelta){ // loop logic. } } void dosomething(){ // 直接在默认的EntityManager中创建一个实体 GameEntry.GetComponent\u003cEntityManager\u003e().Load\u003cEnemy\u003e(new EnemyData()); } 对于实体的销毁，像敌人死亡，特效消失之类的，仅仅只需要设置一个 Alive 属性，即可完成，生命周期由EntityManger自行决断。\n需要注意的是 继承IEntityData的数据模板是会一直复用的，它与 Entity的复用规则不同，后者复用的是Entity所持有的实体，因为它本身只是一系列函数集合且很少会带有数据并不会占用太多的内存，而前者大部分情况下是都是通过读表获取，复杂的实体数据可能会导致内存异常大，所以保留实体数据是EntityManager的默认行为。\nEntitySettings EntityManager可能需要在某些大量对象时使用对象池（Entity），或者内存池(EntityData),但在大多数情况下，框架并不清楚是否需要对象池，或者是需要一个定长周期的物体（子弹或者特效）。\n这个时候需要设置就非常有必要了，可以决断出是否需要且生命周期（keepalive）或者是需要多大的对象池，以及自动孵化的频率了。\n","tags":[""],"title":"EntityManager","type":"post"},{"authors":null,"categories":["Zen"],"content":"简介 Resource 是一个全自动化，且简单易用的资源管理系统,继承于GameComponet实现 ，它内部使用RC的方式来管理资源的引用，且不需要手动显示释放,而是通过拦截finalizer的方式，来达到释放的目的，比手动安全性更高，也更易用。\n它仅提供了两组接口资源加载接口LoadAsset LoadAssetAsync，。并提供了虚拟化的方式加载，在编辑器模式下不会真正的构建AssetBundle包，从而提供开发效率。\nResource也包括流场景构建，可以将整个场景都作为热更新资源。\nFeature 自动化检测文件变动 通过Radix算法，监控资源变动，来自动构建manifest。上层只需要关注资源本身，无需关注AssetBundle包的构建。做到对上层完全无感。\n自动化引用计数 通过 RC+ finalizer，监控资源的引用，来自动释放资源。且无需轮询检查资源的引用计数，提供更好的性能，做到对上层完全无感。也没有手动释放接口，提高安全性和易用性\n自动化冗余剔除 在构建的时候自动收集冗余资源，如像A-\u0026gt;(C,D) B-\u0026gt;(C) 此时(A,D)将会作为一个的bundle，而C则会单独作为一个bundle\nProfile资源使用分析，用以在运行时统计各个资源的引用和加载数\n自定义流处理，支持加密等自定义操作\n多种模式支持\nBuiltin: 内建资源，默认将资源插入母包中。\nRemote: 远程资源模式，仅需要配置远程资源地址即可，所有资源不会在本地存盘，只会在内存中使用，使用完后立即释放，防止被反编译资源\n无感知资源更新 一般出现资源更新的时候，都是先下载到本地，然后再通过加载本地资源的方式实现， 现由FS映射的远程目录，通过分流的方式，可以实现一边从远程直接读取，并copy另外一部分流到本地磁盘，减少重新读盘的情况。 对于下载过程对于玩家而言完全无感，其本身下载速度是可以被控制，当前并没有暴露此接口（因为带宽值是动态变化的，无法根据不同的条件找到一个合理值），只是需要设定一个百分率阈值，内部自动计算下载速度尽可能保证达到预期值。\n淘汰策略 当某个Assetbundle的引用计数为0时候，底层不会立即释放它，而是根据它过往的加载次数判断下一次淘汰次数，越大将会越晚淘汰，当然也提供了强制卸载函数。\n后续计划 现阶段Resource是依赖于Assetbundle 后续会抽象出一层 FS 以提供自定义流提供更多可操作性和安全性。 已实现\nResource现在可以说是完全不能脱离Unity独立运行，这不是一个好的方式，我期望提供更高的抽象满足多个引擎的需求。当完成这一步时只需要在Unity中需要手动实现一个Adaptor即可。\n","date":1680307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680307200,"objectID":"6b8c9d0edb385f55997cba4c6e932ed6","permalink":"https://domyson.github.io/post/zen/2/","publishdate":"2023-04-01T00:00:00Z","relpermalink":"/post/zen/2/","section":"post","summary":"简介 Resource 是一个全自动化，且简单易用的资源管理系统,继承于GameComponet实现 ，它内部使用RC的方式来管理资源的引用，且不需要手动显示释放,而是通过拦截finalizer的方式，来达到释放的目的，比手动安全性更高，也更易用。\n它仅提供了两组接口资源加载接口LoadAsset LoadAssetAsync，。并提供了虚拟化的方式加载，在编辑器模式下不会真正的构建AssetBundle包，从而提供开发效率。\nResource也包括流场景构建，可以将整个场景都作为热更新资源。\nFeature 自动化检测文件变动 通过Radix算法，监控资源变动，来自动构建manifest。上层只需要关注资源本身，无需关注AssetBundle包的构建。做到对上层完全无感。\n自动化引用计数 通过 RC+ finalizer，监控资源的引用，来自动释放资源。且无需轮询检查资源的引用计数，提供更好的性能，做到对上层完全无感。也没有手动释放接口，提高安全性和易用性\n自动化冗余剔除 在构建的时候自动收集冗余资源，如像A-\u003e(C,D) B-\u003e(C) 此时(A,D)将会作为一个的bundle，而C则会单独作为一个bundle\nProfile资源使用分析，用以在运行时统计各个资源的引用和加载数\n自定义流处理，支持加密等自定义操作\n多种模式支持\nBuiltin: 内建资源，默认将资源插入母包中。\nRemote: 远程资源模式，仅需要配置远程资源地址即可，所有资源不会在本地存盘，只会在内存中使用，使用完后立即释放，防止被反编译资源\n无感知资源更新 一般出现资源更新的时候，都是先下载到本地，然后再通过加载本地资源的方式实现， 现由FS映射的远程目录，通过分流的方式，可以实现一边从远程直接读取，并copy另外一部分流到本地磁盘，减少重新读盘的情况。 对于下载过程对于玩家而言完全无感，其本身下载速度是可以被控制，当前并没有暴露此接口（因为带宽值是动态变化的，无法根据不同的条件找到一个合理值），只是需要设定一个百分率阈值，内部自动计算下载速度尽可能保证达到预期值。\n淘汰策略 当某个Assetbundle的引用计数为0时候，底层不会立即释放它，而是根据它过往的加载次数判断下一次淘汰次数，越大将会越晚淘汰，当然也提供了强制卸载函数。\n后续计划 现阶段Resource是依赖于Assetbundle 后续会抽象出一层 FS 以提供自定义流提供更多可操作性和安全性。 已实现\nResource现在可以说是完全不能脱离Unity独立运行，这不是一个好的方式，我期望提供更高的抽象满足多个引擎的需求。当完成这一步时只需要在Unity中需要手动实现一个Adaptor即可。\n","tags":[""],"title":"Resource","type":"post"},{"authors":null,"categories":["zen"],"content":"序 Zen 是一个基于 Unity 引擎的GamePlay框架，脱离 Monobehaviour 开发，致力简化开发流程。内部提供了一个类ECS的架构满足开发，你也可以使用自定义的上层，比如自己实现像MVCC，或者是MVC的上层封装。让开发聚焦在游戏玩法而非一些底层架构上。\nZen的一些设计思想不算是纯粹的OOP，它有ECS的概念，也有type embedding的概念，而且设计概念大部分是参考面过过程和内嵌的设计思想，所以理解曲线会比较困难\n设计目标 无框架化，它之所有不提供是为了更好的设计出不同品类的游戏，而我在近10年的游戏开发生涯中，我始终觉得框架的约束即使最大的约束，因为业务的多样性和非明确性的特点，一般游戏后期的一些奇奇怪怪的需求总是会迫使你绕过框架的约束从而形成屎山code，所以我希望Zen框架本身可以尽可能的简单，让开发者可以自由的去选择框架的约束。你可使用Zen的一部分，或者全部，甚至是都不需要。\n无MonoBehaviour编程设计，解除引擎原始的约束，更自由的编程方式，像之前开发游戏，一个角色身上可能挂在各式各样的组件，一旦后期业务变动很容易出现引用丢失或者维护起来更为困难，而且一些特殊的时候可能还需要设置一下脚本的执行顺序，给维护带来巨大的不便（如我之前所呆的项目各种口口相传的细节规范，让开发痛不欲生）\n模块化，Zen的一大特色，以像C library的方式来组织模块，让模块之间可以互相调用，并且可以互相替换，让开发者可以自由的去选择模块的约束。选择何种内置模块，或者是自定义模块由开发者决定，这也是使用 Zen 唯一的约束，你的模块可以是框架，也可以是Module。\n简单化，Zen 本身只提最必要的一些基础组件，你可以重新实现，而并非是必要的\n自由化，游戏开发是自由的，是创造性的，Zen 不会约束你干什么，你只需要关注你的想法，怎么做取决于你的点子。\n非文档约束性组件控制器绑定，面向对象的模式必然导致代码变得复杂，因使用内嵌代替OOP，但显然C#做不到，需要额外的封装，但过于麻烦不符合Zen的设计哲学，故通过静态泛型约束实现。\n无任何反射调度，提高代码的运行速度。\n高度继承的构建管线，非常完善且易使用基建设计（配置，资源，本地化，网络等）\nZenRpc现在可用了，无关乎网络，无缝与 skynet-go\nZen不鼓励继承，其内部设计也是符合此规范，所以整个拓扑架构更平整\n应用案例 它确实有一些思维上的理解成本，就我个人使用Zen开发过三款独立项目（，一款Roguelike，一款塔防，一款农场经营，这三款项目都使用了Zen框架，完成大部分核心内容只花费了一个月不到的时间，从中也调整过需要设计上的变动，是为了更好的适应游戏开发。原计划是这三款项目的将会上架Steam，但受限于美术资源，可能开发周期会被拉长。\nZen是一个持续迭代的框架，随着后期一些理解和学习也会增删一些内容，也有可能会断更（或许会在断更前开源吧）。\nISystem System 它用于执行游戏运行中的实际逻辑，约束了创建和销毁和执行的方式，它可以拥有数据，也可以拥有逻辑，并且它是泛型全局唯一的，如TimeComponent，NetPollComponent,EnityManager等，它表示一系列相似功能的集合实现。 而且它的每一个类型实现都是全局唯一，除非手动卸载，它的生命周期等同于全局。外部可以直接通过CreateOrGetGameComponent\u0026lt;T\u0026gt;()获取即可,里面所有方法都会由GameEntry负责调度，不需要手动调用，所以内建模块默认行为是只有逻辑。\n// Define a Zen framwork System public class CustomSystem:ISystem { int ISystem.Order =\u0026gt; 1; void ISystem.OnCtor(object userdata = null) { // do something } void ISystem.OnShutdown(){ // do something } } Builtin public class Enitiy Entity需要着重介绍下，它不完全是ECS中的概念，而不全是GameObject,我们可以认为任何单元都是Entity 如网络简介，甚至是玩家身上的装备数据。具体看如何划分\nHybridCLR 暂时还未接入，考虑到版本更新的频率现阶段接入不太现实，而且最近传闻ios将会开放，后续直接DLL的方式也未尝不可。\n目录 ECS\nResource\nDatatable\nNetPollComponent\nEntityManager\nReGoap\n","date":1680307200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1680307200,"objectID":"0d4e742d08a170975d7398a8adde3644","permalink":"https://domyson.github.io/post/zen/0/","publishdate":"2023-04-01T00:00:00Z","relpermalink":"/post/zen/0/","section":"post","summary":"序 Zen 是一个基于 Unity 引擎的GamePlay框架，脱离 Monobehaviour 开发，致力简化开发流程。内部提供了一个类ECS的架构满足开发，你也可以使用自定义的上层，比如自己实现像MVCC，或者是MVC的上层封装。让开发聚焦在游戏玩法而非一些底层架构上。\nZen的一些设计思想不算是纯粹的OOP，它有ECS的概念，也有type embedding的概念，而且设计概念大部分是参考面过过程和内嵌的设计思想，所以理解曲线会比较困难\n设计目标 无框架化，它之所有不提供是为了更好的设计出不同品类的游戏，而我在近10年的游戏开发生涯中，我始终觉得框架的约束即使最大的约束，因为业务的多样性和非明确性的特点，一般游戏后期的一些奇奇怪怪的需求总是会迫使你绕过框架的约束从而形成屎山code，所以我希望Zen框架本身可以尽可能的简单，让开发者可以自由的去选择框架的约束。你可使用Zen的一部分，或者全部，甚至是都不需要。\n无MonoBehaviour编程设计，解除引擎原始的约束，更自由的编程方式，像之前开发游戏，一个角色身上可能挂在各式各样的组件，一旦后期业务变动很容易出现引用丢失或者维护起来更为困难，而且一些特殊的时候可能还需要设置一下脚本的执行顺序，给维护带来巨大的不便（如我之前所呆的项目各种口口相传的细节规范，让开发痛不欲生）\n模块化，Zen的一大特色，以像C library的方式来组织模块，让模块之间可以互相调用，并且可以互相替换，让开发者可以自由的去选择模块的约束。选择何种内置模块，或者是自定义模块由开发者决定，这也是使用 Zen 唯一的约束，你的模块可以是框架，也可以是Module。\n简单化，Zen 本身只提最必要的一些基础组件，你可以重新实现，而并非是必要的\n自由化，游戏开发是自由的，是创造性的，Zen 不会约束你干什么，你只需要关注你的想法，怎么做取决于你的点子。\n非文档约束性组件控制器绑定，面向对象的模式必然导致代码变得复杂，因使用内嵌代替OOP，但显然C#做不到，需要额外的封装，但过于麻烦不符合Zen的设计哲学，故通过静态泛型约束实现。\n无任何反射调度，提高代码的运行速度。\n高度继承的构建管线，非常完善且易使用基建设计（配置，资源，本地化，网络等）\nZenRpc现在可用了，无关乎网络，无缝与 skynet-go\nZen不鼓励继承，其内部设计也是符合此规范，所以整个拓扑架构更平整\n","tags":[""],"title":"Zen Gameplay Framework","type":"post"},{"authors":null,"categories":null,"content":"Redis Remote Dictionary Server,采用 ANSI C 编写的 K-V数据库\nRedis命令\nRedis下载\n类型 string 最大存储值为256mb，底层由SDS(simple dynamic string)实现，优势是访问长度仅需O(1)\nhash\nlist 存储有序字符串，最大2^32-1个元素\nset\n同list，但不允许重复\nsorted set 已排序的都字符串集合，但不允许重复 – 其它\nGEO 地理位置 HyperLogLog 基数统计 Bitsmap bit数组，类似boolean filter redis设计架构 单线程业务，多线程存储，redis6.0引入多线程也仅仅是为了提高解析命令的速度\n虚拟内存\n虚拟内存机制就是暂时把不经常访问的数据(冷数据)从内存交换到磁盘中，从而腾出宝贵的内存空间用于其它需要访问的数据(热数据)。通过VM功能可以实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘。这样就可以避免因为内存不足而造成访问速度下降的问题。\n击穿，穿透，雪崩 击穿 某个key在过期点的时候，突然出现大量请求查找这个key\n穿透 访问一个不存在的key的时候\n雪崩 指缓存中数据大批量到过期时间，访问落到db上，造成db压力过大\n持久化机制 RDB RDB持久化，是指在指定的时间间隔内，执行指定次数的写操作，将内存中的数据集快照写入磁盘中，它是Redis默认的持久化方式。执行完操作后，在指定目录下会生成一个dump.rdb文件，Redis 重启的时候，通过加载dump.rdb文件来恢复数据\n分为手动触发和自动触发\n优点 适合大规模的数据恢复场景，如备份，全量复制等\n缺点 没办法做到实时持久化/秒级持久化。\nAOF 采用日志的形式来记录每个写操作，追加到文件中，重启时再重新执行AOF文件中的命令来恢复数据。它主要解决数据持久化的实时性问题\n优点 数据一致性和完整性更高 缺点 内容越多，文件越大，恢复变慢，它需要将所有命令执行一遍\n高可用 主从 类似mysql主从，master负责写，slave负责读\n哨兵 监视其他节点的状态\n集群 Gossip，HashSlot 16384\nView\n分布式锁 setnx setnx nx [expired]\n优点：实现简单\n缺点：若在分布式中未同步则会造成多个client获取到锁\nredisson 优点：可用性高\n缺点：需要自己循环获取锁，性能消耗高，同setnx的缺点\nredlock 优点：解决了单点问题\n缺点：维护成本高\n持久化 AOF AOF文件中实际存储的是 Redis 协议下的命令记录,把每一次写操作以追加的形式记录在其中以文件的形式刷到磁盘里.\nfsync 策略\n无 fsync : 数据容易丢失\n每秒 fsync : 默认策略，性能正常，由后台线程执行，最多丢失1秒的数据，但文件大小随着时间线性增长，若用来恢复数据会非常缓慢。\n每次写 fsync : 牺牲大部分性能，文件也大，但基本不会丢失数据\nRDB 一种快照机制，每个一段时间会对内存数据进行一次快照，保存在 rdb 文件中\nSAVE 和 BGSAVE 命令分别是同步保存和 fork 子进程保存\nRDB 文件非常紧凑，它保存了 Redis 某个时间点上的数据集。RDB 恢复大数据集时速度要比 AOF 快。但是 RDB 不适合那些对时效性要求很高的业务，因为它只保存了快照，在进行恢复时会导致一些时间内的数据丢失。\n如果数据量很大的话 rdb 它要保存一个完整的数据集 是一个大的工作 如果时间间隔设置的太短，那么严重影响redis的性能 但是按照常规设置的话 如5分钟一次 那么如果宕机或者重启 就会基于上次做rdb的时间，而丢失分钟级的数据\n管道技术 Redis 管道技术可以在服务端未响应时，客户端可以继续向服务端发送请求，并最终一次性读取所有服务端的响应。\n管道技术最显著的优势是提高了 redis 服务的性能。\n事务 批量操作在发送 EXEC 命令前被放入队列缓存。\n收到 EXEC 命令后进入事务执行，事务中任意命令执行失败，其余的命令依然被执行。\n在事务执行过程，其他客户端提交的命令请求不会插入到事务执行命令序列中。\n一个事务从开始到执行会经历以下三个阶段：\n开始事务。 命令入队。 执行事务。 +命令 描述 DISCARD 取消事务，放弃执行事务块内的所有命令。 EXEC 执行所有事务块内的命令。 MULTI 标记一个事务块的开始。 UNWATCH 取消 WATCH 命令对所有 key 的监视。 WATCH key [key ...] 监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。\n集群 概念 Redis集群中的节点都需要打开两个TCP连接。一个连接用于正常的给Client提供服务，比如6379，还有一个额外的端口（通过在这个端口号上加10000）作为数据端口，比如16379。第二个端口用于集群总线，这是一个用二进制协议的点对点通信信道。这个集群总线（Cluster bus）用于节点的失败侦测、配置更新、故障转移授权，等等。客户端从来都不应该尝试和这些集群总线端口通信，它们只应该和正常的Redis命令端口进行通信。注意，确保在你的防火墙中开放着两个端口，否则，Redis集群节点之间将无法通信。\n所有 Redis 节点彼此相连（内部 PING-PONG）机制\n节点 Fail 至少通过集群半数以上的节点检测失效才生效\n客户端只需要连接其中一个节点即可\nRedis-Cluster 负责把物理节点映射到 [0-16383]slot 上, cluster 负责维护 node \u0026lt;-\u0026gt; slot \u0026lt;-\u0026gt; value\nRedis 集群分片 Redis 集群不同一致性哈希，它用一种不同的分片形式，在这种形式中，每个key都是一个概念性（hash slot）的一部分。 Redis集群中内置了 16384 个哈希槽，当需要在 Redis 集群中放置一个 key-value 时，redis 先对key 使用 crc16 算法算出一个结果，然后把结果对 16384 求余数，这样每个 key 都会对应一个编号在 0-16383 之间的哈希槽，redis 会根据节点数量大致均等的将哈希槽映射到不同的节点\n允许添加和删除集群节点。如增加一个新的节点D，那么需要从A、B、C节点上删除一些hash slot给到D。同样地，如果从集群中删除节点A，那么会将A上面的hash slot 移动到B和C，当节点A上是空的时候就可以将其从集群中完全删除。\nRedis 集群主从模式 投票过程需要整个集群的 Master 节点参与，当其中存在与集群半数以上的 Master 节点通讯失败，则剔除此 Master\nMaster-Slave 模式，当集群中有 Master 节点失败的话，则其 Slave 节点将有一个提升为新的 Master 节点。\n如果集群任意 Master 挂掉,若其没有 Slave .集群进入 fail 状态,也可以理解成集群的slot映射 [0-16383] 不完整时进入fail状态.\n如果集群超过半数以上 master 挂掉，无论是否有 slave ，集群进入 fail 状态.\n#主从模式配置 bind 0.0.0.0 port 6379 logfile \u0026#34;6379.log\u0026#34; dbfilename \u0026#34;dump-6379.rdb\u0026#34; daemonize yes rdbcompression yes #slaveof 192.168.81.135 6379 这个配置应用的是slave节点，指定的是 master 节点 # slave-read-only yes 默认 slave 节点只提供读取，可以通过设置 Reids 集群一致性 Redis 集群不能保证强一致性 集群搭建 修改配置文件 # redis.conf文件 #客户端端口 port 7000 #pid文件 pidfile /var/run/redis_6379.pid # 启用集群 cluster-enable yes # 由redis集群自动生成 cluster-config-file nodes.conf # 集群ping-pong超时时间 ms cluster-node-timeout 5000 #是否启用aof appendonly on 名词解释 这几种情况都是从缓存没有获取到数据，大量的并发请求到了数据源，给数据源造成很大压力，从而可能引发问题\n缓存穿透：key对应的数据在数据源并不存在，每次针对此key的请求从缓存获取不到，请求都会到数据源，从而可能压垮数据源。比如用一个不存在的用户id获取用户信息，不论缓存还是数据库都没有，若黑客利用此漏洞进行攻击可能压垮数据库。\n缓存击穿：key对应的数据存在，但在redis中过期，此时若有大量并发请求过来，这些请求发现缓存过期一般都会从后端DB加载数据并回设到缓存，这个时候大并发的请求可能会瞬间把后端DB压垮。\n缓存雪崩：当缓存服务器重启或者大量缓存集中在某一个时间段失效，这样在失效的时候，也会给后端系统(比如DB)带来很大压力。\n优化 使用短的key\n避免使用 keys *：这个命令是阻塞的，使用 SCAN 代替\n设置 key 的过期时间\n线上解决方案 缓存穿透 采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做缓存预热(项目启动前，先加载缓存)操作。 提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。 对查询结果为空的情况也进行缓存，缓存时间设置短一点，或者该key对应的数据insert了之后清理缓存。\n缓存击穿 利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试。\n缓存雪崩 在缓存失效后，通过加锁或者队列来控制读数据库写缓存的线程数量。比如对某个key只允许一个线程查询数据和写缓存，其他线程等待。 不同的key，设置不同的过期时间，让缓存失效的时间点尽量均匀。\n做二级缓存，A1为原始缓存，A2为拷贝缓存，A1失效时，可以访问A2，A1缓存失效时间设置为短期，A2设置为长期\n","date":1669248000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1669248000,"objectID":"de65960d8ed4d7eb16b786bf208d5cae","permalink":"https://domyson.github.io/post/redis/","publishdate":"2022-11-24T00:00:00Z","relpermalink":"/post/redis/","section":"post","summary":"Redis Remote Dictionary Server,采用 ANSI C 编写的 K-V数据库\nRedis命令\nRedis下载\n类型 string 最大存储值为256mb，底层由SDS(simple dynamic string)实现，优势是访问长度仅需O(1)\nhash\nlist 存储有序字符串，最大2^32-1个元素\nset\n同list，但不允许重复\nsorted set 已排序的都字符串集合，但不允许重复 – 其它\nGEO 地理位置 HyperLogLog 基数统计 Bitsmap bit数组，类似boolean filter redis设计架构 单线程业务，多线程存储，redis6.0引入多线程也仅仅是为了提高解析命令的速度\n虚拟内存\n虚拟内存机制就是暂时把不经常访问的数据(冷数据)从内存交换到磁盘中，从而腾出宝贵的内存空间用于其它需要访问的数据(热数据)。通过VM功能可以实现冷热数据分离，使热数据仍在内存中、冷数据保存到磁盘。这样就可以避免因为内存不足而造成访问速度下降的问题。\n击穿，穿透，雪崩 击穿 某个key在过期点的时候，突然出现大量请求查找这个key\n穿透 访问一个不存在的key的时候\n雪崩 指缓存中数据大批量到过期时间，访问落到db上，造成db压力过大\n持久化机制 RDB RDB持久化，是指在指定的时间间隔内，执行指定次数的写操作，将内存中的数据集快照写入磁盘中，它是Redis默认的持久化方式。执行完操作后，在指定目录下会生成一个dump.rdb文件，Redis 重启的时候，通过加载dump.rdb文件来恢复数据\n分为手动触发和自动触发\n优点 适合大规模的数据恢复场景，如备份，全量复制等\n缺点 没办法做到实时持久化/秒级持久化。\nAOF 采用日志的形式来记录每个写操作，追加到文件中，重启时再重新执行AOF文件中的命令来恢复数据。它主要解决数据持久化的实时性问题\n优点 数据一致性和完整性更高 缺点 内容越多，文件越大，恢复变慢，它需要将所有命令执行一遍\n高可用 主从 类似mysql主从，master负责写，slave负责读\n哨兵 监视其他节点的状态\n集群 Gossip，HashSlot 16384\nView\n分布式锁 setnx setnx nx [expired]\n","tags":null,"title":"redis","type":"post"},{"authors":null,"categories":["linux"],"content":"iptables iptables 基于 netfilter 采用一条条规则链表，时间复杂度为O(n)，最主要的是 iptables 专为防火墙设计\nipvs ipvs 同样基于 netfilter，但底层采用的是hash表，索引复杂度为O(1)\n","date":1668816000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1668816000,"objectID":"89d04527c6574802a8b4ad3dde3b8660","permalink":"https://domyson.github.io/post/linux/iptables/","publishdate":"2022-11-19T00:00:00Z","relpermalink":"/post/linux/iptables/","section":"post","summary":"iptables iptables 基于 netfilter 采用一条条规则链表，时间复杂度为O(n)，最主要的是 iptables 专为防火墙设计\nipvs ipvs 同样基于 netfilter，但底层采用的是hash表，索引复杂度为O(1)\n","tags":[""],"title":"iptables and ipvs","type":"post"},{"authors":null,"categories":[""],"content":"前言 其实在cobweb之初就设计了一种编码协议(kproto)，用于内部消息的编码,但因为公司项目长期需要维护以及开发（两款线上，一款开发中），所以一直未对此库进行维护， 而后期在研发的时候，发现需要与多种语言交互，显然 json,xml 不是一个很好的选择，而 protobuf 对弱类型语言支持不友好。\nBenchmark cpu: Intel(R) Core(TM) i9-9900K CPU @ 3.60GHz os: windows11 arch: amd64 format compress rate encode rate decode rate json std 0% 0%( 213.8 ns/op) 0%(1204ns/op) proto v3 -40% -51%(98.36 ns/op) -84%(190.1ns/op) kproto -40% -76% (65.21 ns/op) -95%(62.18ns/op) Feture 快速，比protobuf-v3 基本高出 20%左右\n简单，文件生成方式不是必须的，也是动态设置\n小体积， 基本编码后的二进制与protobuf持平\n流式， 它可以直接读取任意字段而不需要解析出所有字段\n多语言支持 提供了完整的golang和c实现，额外的在go中提供了文件生成，而且在skynet-x 中也是默认编码协议，所以也对Lua提供了支持\n干净， 没有任何隐式内存分配，由外部指定分配器\n无冗余， 可以通过sizeof直接获取需要的内存大小，避免多余的内存浪费\n自带元数据，无需额外的信息\n词法解析器 因为需要和强类型和弱类型进行转换，词法解析器和描述文件需要一个抽象共用类型加以识别，所以对于强类型语言是通过生成描述文件识别的。\nLua5.1 是没有整数类型，需要区分浮点和整形的区别，这涉及到最终编码的尺寸，kproto对它们进行了区分\nLua table 纯数组table和hash table 的编码方式也是不同的，这依赖于 table 在底层的结构，若非必要不要混合。\n代码生成器 强类型和弱类型的识别是有很大区别，所以我对Lua 这边进行了直接解析，简单来说是直接通过 Lexer 生成此消息结构的元信息.\n强类型语言为了减少反射，我们需要通过文件描述来提供其成员或字段的类型以及位置而非通过反射，这个在编译期间就可以确定了而非运行时。\n设计思路 减少内存分配\n为了减少i/o和内存压力，最简单的办法是让一个字节能包含更多的消息， 如一个32bit的整形，它也许只需要1byte即可,其二不同的分配大小影响执行速度，（如32byte和64kb是存在明显区别）， 所以需要动态计算分配尺寸。\nunsafe.Pointer\n显然反射是所有带运行时语言的一个痛点，而通过 unsafe.Pointer 能明显提高执行速率，所以 kproto 采用了大量非安全指针操作，所以关于生成文件尽量不要进行任何编辑，以免造成内存偏移位置错误。\nc中的实现则是直接计算内存地址偏移位\n使用\nkproto 支持两种模式，其一类似.proto文件，定义模板，其二直接使用库进行解析,这里拿lua举例，其他语言类似\nlocal kproto = require(\u0026#34;kproto\u0026#34;) -- 基于文件结构的生成 local err = kproto.load(\u0026#34;file path or dir path\u0026#34;) -- 注意 此函数执行结果在当前节点是共享的，所以只需要加载一次，并返回一个错误（string） if err~=nil then -- do something end -- 此时返回的data是 `userdata`,不要尝试访问它 local data ,err = kproto.marshal(string,table) -- 仅返回一个错误，并将具体数据映射到传入的 `table` 中 local err = kproto.unmarshal(string,data) -- 亦或是过程式 local offset = kproto.put(buf[offset],integer) offset =kporot.pug(buf[offset],string) offset = kproto.get(buf[offset],integer) offset = kproto.get(buf[offset],string) -- 迭代器模式 kproto.iter(buf,function(typ,value) // do something return false -- whether exit iter end) kproto file\npackage gen // 影响到文件的scope // 注释 enum Foo { // 一个枚举，最终会转换为 uint32 类型进行编码 A B C } message empty {} // 一个空消息 message PhoneNumber{ string number integer type // 整形的抽象类型，具体编码和长度取决于当前语言，包含(i16,u16,i32,u32,i64,u64) float f // 浮点的抽象类型，具体编码和长度取决于当前语言 (f32,f64) } message Person{ string name integer id string email *PhoneNumber phones // 嵌套类型的数组 PhoneNumber phone // 嵌套类型 } message AddressBook { *Person person } 后续可能考虑直接读取protobuf,免费的提示和高亮的插件 :)\nLua 序列化 kproto 开发过程的附加产物，唯一的区别仅能在lua侧使用,不支持userdata,function,thread\nkproto 产生的会导致新的内存分配，记得释放它，不然会造成GC\n这里特别注明，userdata不支持仅仅是为了兼容节点通讯。因为它本质上一个8byte的整形(x64),而其他物理机或者进程的内存地址是不同的\nexcel 数据表支持 惰性加载，数据表索引，二进制编码\n未来将支持 rpc 定义\n指定字段偏移解码（beta）\n","date":1663718400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1663718400,"objectID":"a4c9ce8bbd8f4c5de00197a4e521232e","permalink":"https://domyson.github.io/post/kproto/","publishdate":"2022-09-21T00:00:00Z","relpermalink":"/post/kproto/","section":"post","summary":"前言 其实在cobweb之初就设计了一种编码协议(kproto)，用于内部消息的编码,但因为公司项目长期需要维护以及开发（两款线上，一款开发中），所以一直未对此库进行维护， 而后期在研发的时候，发现需要与多种语言交互，显然 json,xml 不是一个很好的选择，而 protobuf 对弱类型语言支持不友好。\nBenchmark cpu: Intel(R) Core(TM) i9-9900K CPU @ 3.60GHz os: windows11 arch: amd64 format compress rate encode rate decode rate json std 0% 0%( 213.8 ns/op) 0%(1204ns/op) proto v3 -40% -51%(98.36 ns/op) -84%(190.1ns/op) kproto -40% -76% (65.21 ns/op) -95%(62.18ns/op) ","tags":[""],"title":"kproto 编码协议","type":"post"},{"authors":null,"categories":["skynet-x"],"content":"简介 skynet-x是基于actor 消息的服务框架，那么我们需要定义一套标准且高效的消息结构\nProcessor 一个伪线程的逻辑处理器概念，它分为独占和负载两种模式。\n独占Processor是为了更好的处理实时性更高的业务，它不会被其他任务抢占\n负载Processor又可分为两种运行态，均匀的处理业务以及从其他Processor上偷窃任务，尽量保证Processor不会过于闲置，除此之外，负载Processor可随着任务的变动而增加（不会超过最大设定值），特别的当某个任务陷入”死循环”或者是超出设定运行阈值的时候会重新创建一个Processor，并让之前的挂起（在C版本中将会被强制关闭）。\nC版本和Go版本调度和设计上差异不大，但一些细节上的处理可能不同，因为C可以提供更多的底层控制\nPID 一个 message 最重要的是消息地址，如果一个消息没有地址的话我们称为 dead-letter。 那么我们通过Pid 标定一个地址类型，\n它表示该服务的唯一id (本质上是一个uint64)的类习惯，它一定能确保在当前节点以及集群中唯一的。\n在服务本身未被关闭的时候，pid一定不会产生变动，但重新启动节点之后，它的值可能会发生改变，因为所有服务默认都是并发启动，除非手动指定了关系(这也是它与skynet-x的区别)，所以不要尝试保存这个pid\n一旦能确定了一个pid的话，就可以通过 skynet.send(pid,cmd,...) or skynet.call(ti,pid,cmd,...) 将其发送出去了。\n服务的消息队列 Actor 模型最重要的的概念是 mailbox,它代表了一个实体需要处理的队列容器，\n得益于go的简单性，可以使用 channel 来实现，但这种方式的实现性能不高，因为 channel 底层的结构使用的是互斥锁，\n所以我采用了mpsc 实现了无锁队列，性能更优于 channel\nTODO: 吞吐量对比\n消息的接受和发送 发送 用户不需要构建这个结构体，仅仅需要指定 destination 以及需要发送的数据，而且 skynet-x 消息投递被设计成不允许发送 nil 因为这是无任何意义的，相反它还会消耗服务投递的性能，如果确实有这种需求，可以发送 struct{}{}。\n而且消息发送成功只能代表被 mailbox 接受了，不代表会被立即处理，而不会一定处理成功，所以需要正确理解这种方式。\n如果发送失败，那么一定失败，并返回一个错误\n接收 接受回调只包含5个关键参数 context,addr,session,mtype,argument\ncontext 其实就是创建服务用户指定的结构指针，用于数据传递和状态修改\nsession 主要的作用是用以区分这条消息是否是同步请求， 如若大于0，则其值就是请求序列号,只需要通过 skynet.ret(msg) 返回即可\nmtype 仅仅是一个消息类别的区分，类似于消息号，用户可自行定义，可作为rpc消息类型\nargument 才是真实的数据，它可以是任意值，特别的，在lua中这个值是会被解构，在跨节点通讯这个值恒为 []byte，当不需要时记得 skynet.free 1.4.0 这个由底层回收，用户不用关心\n异步消息 异步消息通过 skynet.send的方式进行投递，它只在乎这个消息有没有正确到达到对点服务，而不关心是否能被对点服务正确处理，并返回一个 error\n同步消息 同步消息通过 skynet.call的方式进行投递，它会阻塞当前coroutine，它也返回一个错误，能解除此次阻塞只有两个条件，对点服务skynet.ret 或者达到了指定超时时间，\n超时一定需要大于10ms,这是内置计时器的最小精度,所以特别在远程通讯的时候要考虑到 i/o 的延时\n","date":1658448000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1658448000,"objectID":"d6ece5273330faebe488d552043d3176","permalink":"https://domyson.github.io/post/skynet/1/","publishdate":"2022-07-22T00:00:00Z","relpermalink":"/post/skynet/1/","section":"post","summary":"简介 skynet-x是基于actor 消息的服务框架，那么我们需要定义一套标准且高效的消息结构\nProcessor 一个伪线程的逻辑处理器概念，它分为独占和负载两种模式。\n独占Processor是为了更好的处理实时性更高的业务，它不会被其他任务抢占\n负载Processor又可分为两种运行态，均匀的处理业务以及从其他Processor上偷窃任务，尽量保证Processor不会过于闲置，除此之外，负载Processor可随着任务的变动而增加（不会超过最大设定值），特别的当某个任务陷入”死循环”或者是超出设定运行阈值的时候会重新创建一个Processor，并让之前的挂起（在C版本中将会被强制关闭）。\nC版本和Go版本调度和设计上差异不大，但一些细节上的处理可能不同，因为C可以提供更多的底层控制\nPID 一个 message 最重要的是消息地址，如果一个消息没有地址的话我们称为 dead-letter。 那么我们通过Pid 标定一个地址类型，\n它表示该服务的唯一id (本质上是一个uint64)的类习惯，它一定能确保在当前节点以及集群中唯一的。\n在服务本身未被关闭的时候，pid一定不会产生变动，但重新启动节点之后，它的值可能会发生改变，因为所有服务默认都是并发启动，除非手动指定了关系(这也是它与skynet-x的区别)，所以不要尝试保存这个pid\n一旦能确定了一个pid的话，就可以通过 skynet.send(pid,cmd,...) or skynet.call(ti,pid,cmd,...) 将其发送出去了。\n服务的消息队列 Actor 模型最重要的的概念是 mailbox,它代表了一个实体需要处理的队列容器，\n得益于go的简单性，可以使用 channel 来实现，但这种方式的实现性能不高，因为 channel 底层的结构使用的是互斥锁，\n所以我采用了mpsc 实现了无锁队列，性能更优于 channel\nTODO: 吞吐量对比\n消息的接受和发送 发送 用户不需要构建这个结构体，仅仅需要指定 destination 以及需要发送的数据，而且 skynet-x 消息投递被设计成不允许发送 nil 因为这是无任何意义的，相反它还会消耗服务投递的性能，如果确实有这种需求，可以发送 struct{}{}。\n而且消息发送成功只能代表被 mailbox 接受了，不代表会被立即处理，而不会一定处理成功，所以需要正确理解这种方式。\n如果发送失败，那么一定失败，并返回一个错误\n接收 接受回调只包含5个关键参数 context,addr,session,mtype,argument\ncontext 其实就是创建服务用户指定的结构指针，用于数据传递和状态修改\nsession 主要的作用是用以区分这条消息是否是同步请求， 如若大于0，则其值就是请求序列号,只需要通过 skynet.ret(msg) 返回即可\nmtype 仅仅是一个消息类别的区分，类似于消息号，用户可自行定义，可作为rpc消息类型\nargument 才是真实的数据，它可以是任意值，特别的，在lua中这个值是会被解构，在跨节点通讯这个值恒为 []byte，当不需要时记得 skynet.free 1.4.0 这个由底层回收，用户不用关心\n异步消息 异步消息通过 skynet.send的方式进行投递，它只在乎这个消息有没有正确到达到对点服务，而不关心是否能被对点服务正确处理，并返回一个 error\n","tags":[],"title":"message","type":"post"},{"authors":null,"categories":["skynet-x"],"content":"工作中曾经开发了一个cobweb的分布式服务器框架（基于golang,c）,但是在实际开发过程中代码难以维护以及更新，主要是每次都需要跨平台进行编译，特别是cgo 往往需要指定平台的系统库,而且一些不规范的使用方式造成无法充分发挥多核的优势，可以参见 关于Go协程的思考 虽然1.16 支持抢占式，但错误的使用方式依然造成了cpu过高的问题。，后续重新设计了skynet-x 是一个actor模型分布式服务框架，使用go编写。\n尽管Actor模型和CSP模型各有所有长，为什么不采用CSP主要有两方面考虑。\nCSP模式使用尽管很简单，但是一个致命的问题是无法控制消息的优先级，当然若只处理一个Channel那可以规避，那么为啥还需要使用CSP,而且像go channel 本身是基于互斥锁（1.16）实现，且无法进行优化和更加精细的控制，只能依赖于runtime的调度。（网上所说什么时候触发调度，我认为channel不能包含其中，它本质也是加锁导致切换） 隔离性太弱，后续一些新的channel引入也会造成破坏性修改，而且 select-case模式等待的channel会随着数量的增加性能会慢慢减弱。 它是一个年轻的框架，仅仅经历了两款项目的迭代 现在版本为 v1.6.0 2023-05-28\n羽翼军团 v1.3.0 我在民国淘古玩 v.1.3.5 与skynet的差异 增加了独占进程的概念，对于一些性能敏感的服务可以绕过公平调度的原则。（公平调度是一个很普遍但并非最优解的调度策略，但对于需要占用资源较多的进程就显得无力）\n使用协程而非线程，一个好处是对于一些假死服务我们可以重新启动它，其它代价远小于线程（尽管协程的开销很低，但我们尽量保证不会被滥用）\n一个简单的二进制文件，skynet修改了lua部分虚拟机源码，而且大部分实现都是基于lua实现，而我设计的是一个将脚本语言作为可选项的插件。\n所有库都是底层语言的实现方式，可控制力和性能更好，完全将业务和底层区分方便同时进行维护\n无感的集群交互方式，调用其他服务（无论在不在本地）就像普通消息那样简单，不需要像skynet需要显示调用cluster。\n进程支持错误重启且消息不会丢失（beta)\n支持后续的DSL\n在2024/03我正计划重新用C实现了一版以提供更好的性能和更底层的控制\n特性 支持纯Lua开发，方便更快的开发业务。\nmysql,redis client支持,值得注意的是这些库都是作为插件实现，跟主库关联不大，需要编译时指定tags\nnative网络支持，对于golang的网络模型而言它不是一个实现高性能的解决方案，尤其是对大量长连接的情况，，特别是cgo 往往需要指定平台的系统库,而且一些不规范的使用方，可参见golang的协程思考\n内置集群组件 sktpmd,易于实现分布式\n隐藏的数据编码，对业务不透明，提供比protobuf-v3 更快的编码 kproto\n超快的性能，完全摒弃interface{}以及各种抽象，采用unsafe.Pointer的方式传递数据（仅底层，上层无须关心）\n基于 slab算法实现的无锁内存分配器zmalloc，比sync.Pool更快\n优势 skynet-x 是过程式以及低抽象的架构。纯函数也更贴合职责单一的原则，也方便后续运行时替换,而低抽象是因为go interface 并非零成本抽象，它有一定的性能代价。所以整个skynet-x 没有任何接口定义。\nskynet-x仅需要一个执行文件，大小仅仅5.78mb,默认运行内存仅仅 2.2mb，\n65535 Lua服务仅占用1.8GB,也就是每个 Lua服务 仅占用 28.8kb\n65535 纯go服务仅占用120mb,每个pure go服务仅占用 1.9kb\n更快的zmalloc内存分配器\n纯C版本持续开发中。。。\n目录大纲 processor\nsktpmd\nsocket\nzmalloc\n","date":1655683200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1655683200,"objectID":"2721b8e52059cc5dc316d1c22304c8ba","permalink":"https://domyson.github.io/post/skynet/0/","publishdate":"2022-06-20T00:00:00Z","relpermalink":"/post/skynet/0/","section":"post","summary":"工作中曾经开发了一个cobweb的分布式服务器框架（基于golang,c）,但是在实际开发过程中代码难以维护以及更新，主要是每次都需要跨平台进行编译，特别是cgo 往往需要指定平台的系统库,而且一些不规范的使用方式造成无法充分发挥多核的优势，可以参见 关于Go协程的思考 虽然1.16 支持抢占式，但错误的使用方式依然造成了cpu过高的问题。，后续重新设计了skynet-x 是一个actor模型分布式服务框架，使用go编写。\n尽管Actor模型和CSP模型各有所有长，为什么不采用CSP主要有两方面考虑。\nCSP模式使用尽管很简单，但是一个致命的问题是无法控制消息的优先级，当然若只处理一个Channel那可以规避，那么为啥还需要使用CSP,而且像go channel 本身是基于互斥锁（1.16）实现，且无法进行优化和更加精细的控制，只能依赖于runtime的调度。（网上所说什么时候触发调度，我认为channel不能包含其中，它本质也是加锁导致切换） 隔离性太弱，后续一些新的channel引入也会造成破坏性修改，而且 select-case模式等待的channel会随着数量的增加性能会慢慢减弱。 它是一个年轻的框架，仅仅经历了两款项目的迭代 现在版本为 v1.6.0 2023-05-28\n羽翼军团 v1.3.0 我在民国淘古玩 v.1.3.5 与skynet的差异 增加了独占进程的概念，对于一些性能敏感的服务可以绕过公平调度的原则。（公平调度是一个很普遍但并非最优解的调度策略，但对于需要占用资源较多的进程就显得无力）\n使用协程而非线程，一个好处是对于一些假死服务我们可以重新启动它，其它代价远小于线程（尽管协程的开销很低，但我们尽量保证不会被滥用）\n一个简单的二进制文件，skynet修改了lua部分虚拟机源码，而且大部分实现都是基于lua实现，而我设计的是一个将脚本语言作为可选项的插件。\n所有库都是底层语言的实现方式，可控制力和性能更好，完全将业务和底层区分方便同时进行维护\n无感的集群交互方式，调用其他服务（无论在不在本地）就像普通消息那样简单，不需要像skynet需要显示调用cluster。\n进程支持错误重启且消息不会丢失（beta)\n支持后续的DSL\n在2024/03我正计划重新用C实现了一版以提供更好的性能和更底层的控制\n","tags":null,"title":"skynet-x 服务器框架简介","type":"post"},{"authors":null,"categories":["skynet-x"],"content":"简介 sktpmd模块是skynet-x底层集群模块，它承担了skynet-x网络节点之间的通讯职能。全名为(skynet port managment daemon)\n架构 sktpmd 为了满足对等网络的性质，所以每次和其他节点建立连接是有两条连接， 当A节点于B节点建立连接，首先A节点发送握手等待B确认，B确认完成之后重复走A的流程，这样一个双向连接就被建立了起来，1.6.0改变了个行为，对于像存在类似缓存，或者数据中心的业务而言的单向节点而言，只需要一条连接即可，节省资源。\nsktpmd现在支持原始的tcp,udp,unix协议，后续规划可能由reliable udp实现，降低集群通讯延时并提供更好的性能和时延性。\n远程命名服务，通过内置命令生成唯一的Name，通过Name来与其他节点通讯是友好的。\n使用 启动也非常简单，无须任何代码，仅仅只需要在 conf.conf 中配置一下即可，使用的时候跟节点内通讯无任何区别。因为我已经作平了本地和节点之间的差异。\n内部均由kproto进行编码,提供更快的序列化方式。\nexample call\nskynet-x.send(\u0026#34;host:port@name\u0026#34;,\u0026#34;rpc\u0026#34;...) -- 通过域名或者地址+端口的形式和其他节点进行通讯 skynet-x.send(\u0026#34;alias\u0026#34;,\u0026#34;rpc\u0026#34;,...) -- 通过别名 skynet-x.send(pid, \u0026#34;rpc\u0026#34;,...) -- 通过pid亦可 tunnel 既然节点之间是双向连接，所以连接数量为 f(n) = n²-n，如果节点过的时候，势必造成 socket fd 消耗殆尽，\n基于这个问题，可以通过内置的tun，来设置代理，这么一来，tun的作用相当于这个集群节点的网关。因为其内部的节点相对于其他 tun 代理是不可见的，\n通过配置tun的规则开启多个，则可以实现业务拆分。\n2022-10-07 此模块被弃用，可以用多节点转接的方式或代理的方式做到，如 send(\u0026#34;n1.n2.n3@name\u0026#34;)\n服务发现 sktpmd 提供了一套服务发现机制，但其运作原理是不同于 etcd 或者 consul,它本身是一个惰性发现，它不需要一个中心服维持它们的关系。\nsktpmd整个发现流程是基于 gossip 算法来发现的,但一些api依然可以主动触发，v1.6.0 这个模块将保留，因为集群模式的逻辑改变了\nv1.6.0集群建立 v1.5.0 之前节点之间都是双向链接，但考虑到一个单向服务器，如 dns server,conf server 等，大部分是 request/response 模式，惰性连接的收益很大，所以去除之前的一些设计。\n网络底层 参考 Go协程的思考,在linux下，使用了 epoll。所以尽量部署到 linux 下以发挥更好的性能\n","date":1653868800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1653868800,"objectID":"7c2f13d4a2dcd13ba2c24fecbbfb98fe","permalink":"https://domyson.github.io/post/skynet/3/","publishdate":"2022-05-30T00:00:00Z","relpermalink":"/post/skynet/3/","section":"post","summary":"简介 sktpmd模块是skynet-x底层集群模块，它承担了skynet-x网络节点之间的通讯职能。全名为(skynet port managment daemon)\n架构 sktpmd 为了满足对等网络的性质，所以每次和其他节点建立连接是有两条连接， 当A节点于B节点建立连接，首先A节点发送握手等待B确认，B确认完成之后重复走A的流程，这样一个双向连接就被建立了起来，1.6.0改变了个行为，对于像存在类似缓存，或者数据中心的业务而言的单向节点而言，只需要一条连接即可，节省资源。\nsktpmd现在支持原始的tcp,udp,unix协议，后续规划可能由reliable udp实现，降低集群通讯延时并提供更好的性能和时延性。\n远程命名服务，通过内置命令生成唯一的Name，通过Name来与其他节点通讯是友好的。\n使用 启动也非常简单，无须任何代码，仅仅只需要在 conf.conf 中配置一下即可，使用的时候跟节点内通讯无任何区别。因为我已经作平了本地和节点之间的差异。\n内部均由kproto进行编码,提供更快的序列化方式。\nexample call\nskynet-x.send(\"host:port@name\",\"rpc\"...) -- 通过域名或者地址+端口的形式和其他节点进行通讯 skynet-x.send(\"alias\",\"rpc\",...) -- 通过别名 skynet-x.send(pid, \"rpc\",...) -- 通过pid亦可 tunnel 既然节点之间是双向连接，所以连接数量为 f(n) = n²-n，如果节点过的时候，势必造成 socket fd 消耗殆尽，\n基于这个问题，可以通过内置的tun，来设置代理，这么一来，tun的作用相当于这个集群节点的网关。因为其内部的节点相对于其他 tun 代理是不可见的，\n通过配置tun的规则开启多个，则可以实现业务拆分。\n2022-10-07 此模块被弃用，可以用多节点转接的方式或代理的方式做到，如 send(\"n1.n2.n3@name\")\n服务发现 sktpmd 提供了一套服务发现机制，但其运作原理是不同于 etcd 或者 consul,它本身是一个惰性发现，它不需要一个中心服维持它们的关系。\nsktpmd整个发现流程是基于 gossip 算法来发现的,但一些api依然可以主动触发，v1.6.0 这个模块将保留，因为集群模式的逻辑改变了\nv1.6.0集群建立 v1.5.0 之前节点之间都是双向链接，但考虑到一个单向服务器，如 dns server,conf server 等，大部分是 request/response 模式，惰性连接的收益很大，所以去除之前的一些设计。\n网络底层 参考 Go协程的思考,在linux下，使用了 epoll。所以尽量部署到 linux 下以发挥更好的性能\n","tags":null,"title":"sktpmd","type":"post"},{"authors":null,"categories":["skynet-x"],"content":"无论是对于C版本还是Go版本的skynet-x而言，一个高效的内存分配器可以提高内存的使用效率，这里效率无论是对于内存碎片亦或是GC而言，都是一种更高效的手段\n基于 SLAB 算法的分段内存分配器 SLAB 最开始是阅读 linux 源码学习的算法，在skynet-x中它确实有更优秀的性能，因为它直接分配了一块大共用内存，所以不会产生任何GC和真实分配,但在业务开发过程中，一旦忘记释放 那么这段内存将不能再被使用和获取了（也就是野指针），直到程序结束。最后的保守策略依然会向runtime申请内存，将会导致内存占用过高。\n而且内置的Debug模式也无法定位到这个指针，原因在于 golang 堆栈伸缩会导致指针地址变动，所以 Debug 只能定位到存在 memory-leak，而无法知道具体位置。若需要具体位置则需要hook这个调用栈，性能方面得不偿失\n基于 sync.Pool 的分段内存分配器 将不同size的buffer放入不同的池中，按需进行分配，减少race的开销，这个方法虽然简单，但是性能是低于 slab-allocator。\n但它确实能减轻心智负担，代价就是牺牲了部分性能以及gc压力，但这也是skynet-x默认使用的策略。如果需要使用可以在编译指令中指明slab\nZmalloc zmlloc 本身也是 slab的升级版本，增加可伸缩链表实现对于预分配内存额外部分的缓冲池。\n在24个线程的cpu条件测试结果如下,zmalloc保持了一种稳定的时间复杂度，额外产生的内存分配也很少\n- time(ns) alloc/op(B) slab-128 23.5 1 sync.Pool-128 2490 65562 zmalloc-128 43.31 16 slab-256 24 256 sync.Pool-256 2204 65562 zmalloc-256 44 16 slab-1024 92 1024 sync.Pool-1024 2490 65562 zmalloc-1024 49 17 slab-4096 365 4096 sync.Pool-4096 2210 65562 zmalloc-4096 45 23 API skynet.zalloc(n) 用以分配指定大小的内存块，考虑到 64在go中为tiny-size，直接会从P上分配，所以zmalloc分配块从128开始\nskynet.zrealloc(buf,n) realloc函数会先检查buf，确保是否需要重新分配内存\nskynet.zmemmove(buf,data)\nskynet.zfree(buf) 释放一段内存,对于slab 而言，它会检查buf的地址是否属于当前class，然后判断是否属于其中的某个segment,否则会继续使用系统的gc。\n","date":1650499200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1650499200,"objectID":"f01d7acd53f6f18bce89903b0f69f5d5","permalink":"https://domyson.github.io/post/skynet/5/","publishdate":"2022-04-21T00:00:00Z","relpermalink":"/post/skynet/5/","section":"post","summary":"无论是对于C版本还是Go版本的skynet-x而言，一个高效的内存分配器可以提高内存的使用效率，这里效率无论是对于内存碎片亦或是GC而言，都是一种更高效的手段\n基于 SLAB 算法的分段内存分配器 SLAB 最开始是阅读 linux 源码学习的算法，在skynet-x中它确实有更优秀的性能，因为它直接分配了一块大共用内存，所以不会产生任何GC和真实分配,但在业务开发过程中，一旦忘记释放 那么这段内存将不能再被使用和获取了（也就是野指针），直到程序结束。最后的保守策略依然会向runtime申请内存，将会导致内存占用过高。\n而且内置的Debug模式也无法定位到这个指针，原因在于 golang 堆栈伸缩会导致指针地址变动，所以 Debug 只能定位到存在 memory-leak，而无法知道具体位置。若需要具体位置则需要hook这个调用栈，性能方面得不偿失\n基于 sync.Pool 的分段内存分配器 将不同size的buffer放入不同的池中，按需进行分配，减少race的开销，这个方法虽然简单，但是性能是低于 slab-allocator。\n但它确实能减轻心智负担，代价就是牺牲了部分性能以及gc压力，但这也是skynet-x默认使用的策略。如果需要使用可以在编译指令中指明slab\nZmalloc zmlloc 本身也是 slab的升级版本，增加可伸缩链表实现对于预分配内存额外部分的缓冲池。\n在24个线程的cpu条件测试结果如下,zmalloc保持了一种稳定的时间复杂度，额外产生的内存分配也很少\n- time(ns) alloc/op(B) slab-128 23.5 1 sync.Pool-128 2490 65562 zmalloc-128 43.31 16 slab-256 24 256 sync.Pool-256 2204 65562 zmalloc-256 44 16 slab-1024 92 1024 sync.Pool-1024 2490 65562 zmalloc-1024 49 17 slab-4096 365 4096 sync.Pool-4096 2210 65562 zmalloc-4096 45 23 API skynet.zalloc(n) 用以分配指定大小的内存块，考虑到 64在go中为tiny-size，直接会从P上分配，所以zmalloc分配块从128开始\nskynet.zrealloc(buf,n) realloc函数会先检查buf，确保是否需要重新分配内存\n","tags":null,"title":"zmalloc","type":"post"},{"authors":null,"categories":["Go"],"content":"结构分析 type Pool struct { noCopy noCopy local unsafe.Pointer // P 本地池，固定尺寸，实际结构 [P]poolLocal，类似 void* 并附加长度构成了一个数组 localSize uintptr // size of the local array victim unsafe.Pointer // local from previous cycle victimSize uintptr // size of victims array New func() any } type poolChain struct{ head *poolChainElt tail *poolChainElt } type poolChainElt struct{ // 一个双向链表 poolDequeue next,prev *poolChainElt } type poolDequeue struct{ headtail uint64 vals []eface } type eface struct{ // 数据的真实内存分配，包括一个类型描述和实际数据 typ,val unsafe.Pointer } type poolLocalInternal struct{ private any // p的私有缓冲区 shared poolChain // 公共缓冲区 } type poolLocal struct{ poolLocalInternal pad [128-unsafe.Sizeof(poolLocalInternal{})%128]byte // 应该是补位，可以确保刚好占满一个 cache line 加速访问 } 申请释放 func (p *Pool) pin() (*poolLocal, int) { pid := runtime_procPin() // 将当前G和P绑定，并返回P的id s := runtime_LoadAcquintptr(\u0026amp;p.localSize) // load-acquire l := p.local // load-consume if uintptr(pid) \u0026lt; s { // 主要是P的数量可能会变动 重新找一个 return indexLocal(l, pid), pid } return p.pinSlow() } func (p *Pool) pinSlow() (*poolLocal, int) { runtime_procUnpin() // 禁止 P 抢占，否则当前G会被放回本地或者全局队列，当时之后G不一定在现在这个P上 allPoolsMu.Lock() defer allPoolsMu.Unlock() pid := runtime_procPin() s := p.localSize l := p.local if uintptr(pid) \u0026lt; s { // double check return indexLocal(l, pid), pid } if p.local == nil { // 如果本地队列为空，那么此时Pool没被初始化，加入全局池引用 allPools = append(allPools, p) } size := runtime.GOMAXPROCS(0) // 查看现在P的个数 local := make([]poolLocal, size) // 为这个Pool分配跟P数量相同的本地池 atomic.StorePointer(\u0026amp;p.local, unsafe.Pointer(\u0026amp;local[0])) // store-release runtime_StoreReluintptr(\u0026amp;p.localSize, uintptr(size)) // store-release return \u0026amp;local[pid], pid // 返回当前和P绑定的本地池 } func (p *Pool) Get() any { if race.Enabled { race.Disable() } l, pid := p.pin() // 先找本地池 x := l.private l.private = nil if x == nil { // 如果没有，那么从全局池找 // Try to pop the head of the local shard. We prefer // the head over the tail for temporal locality of // reuse. x, _ = l.shared.popHead() if x == nil { x = p.getSlow(pid) } } runtime_procUnpin() //释放P，让其可以被抢占 if race.Enabled { race.Enable() if x != nil { race.Acquire(poolRaceAddr(x)) } } if x == nil \u0026amp;\u0026amp; p.New != nil { x = p.New() } return x } // Put adds x to the pool. func (p *Pool) Put(x any) { if x == nil { return } if race.Enabled { if fastrandn(4) == 0 { // Randomly drop x on floor. return } race.ReleaseMerge(poolRaceAddr(x)) race.Disable() } l, _ := p.pin() // 老规矩，先禁止P被抢占 if l.private == nil { // 本地没有 则先放入本地 l.private = x } else { l.shared.pushHead(x) // 否则放入全局 } runtime_procUnpin() if race.Enabled { race.Enable() } } GC 其实很好理解，正好是一次二级缓冲模型，第一次gc会将local放入 victim，第二gc victim不为空才会真正清理，local不会参与gc\nfunc poolCleanup() for _, p := range oldPools { p.victim = nil p.victimSize = 0 } for _, p := range allPools { p.victim = p.local p.victimSize = p.localSize p.local = nil p.localSize = 0 } oldPools, allPools = allPools, nil ","date":1649980800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649980800,"objectID":"f1129f482717cb8fdef809fcdb66e0d3","permalink":"https://domyson.github.io/post/lang/sync.pool/","publishdate":"2022-04-15T00:00:00Z","relpermalink":"/post/lang/sync.pool/","section":"post","summary":"结构分析 type Pool struct { noCopy noCopy local unsafe.Pointer // P 本地池，固定尺寸，实际结构 [P]poolLocal，类似 void* 并附加长度构成了一个数组 localSize uintptr // size of the local array victim unsafe.Pointer // local from previous cycle victimSize uintptr // size of victims array New func() any } type poolChain struct{ head *poolChainElt tail *poolChainElt } type poolChainElt struct{ // 一个双向链表 poolDequeue next,prev *poolChainElt } type poolDequeue struct{ headtail uint64 vals []eface } type eface struct{ // 数据的真实内存分配，包括一个类型描述和实际数据 typ,val unsafe.Pointer } type poolLocalInternal struct{ private any // p的私有缓冲区 shared poolChain // 公共缓冲区 } type poolLocal struct{ poolLocalInternal pad [128-unsafe.Sizeof(poolLocalInternal{})%128]byte // 应该是补位，可以确保刚好占满一个 cache line 加速访问 } 申请释放 func (p *Pool) pin() (*poolLocal, int) { pid := runtime_procPin() // 将当前G和P绑定，并返回P的id s := runtime_LoadAcquintptr(\u0026p.localSize) // load-acquire l := p.local // load-consume if uintptr(pid) \u003c s { // 主要是P的数量可能会变动 重新找一个 return indexLocal(l, pid), pid } return p.pinSlow() } func (p *Pool) pinSlow() (*poolLocal, int) { runtime_procUnpin() // 禁止 P 抢占，否则当前G会被放回本地或者全局队列，当时之后G不一定在现在这个P上 allPoolsMu.Lock() defer allPoolsMu.Unlock() pid := runtime_procPin() s := p.localSize l := p.local if uintptr(pid) \u003c s { // double check return indexLocal(l, pid), pid } if p.local == nil { // 如果本地队列为空，那么此时Pool没被初始化，加入全局池引用 allPools = append(allPools, p) } size := runtime.GOMAXPROCS(0) // 查看现在P的个数 local := make([]poolLocal, size) // 为这个Pool分配跟P数量相同的本地池 atomic.StorePointer(\u0026p.local, unsafe.Pointer(\u0026local[0])) // store-release runtime_StoreReluintptr(\u0026p.localSize, uintptr(size)) // store-release return \u0026local[pid], pid // 返回当前和P绑定的本地池 } func (p *Pool) Get() any { if race.Enabled { race.Disable() } l, pid := p.pin() // 先找本地池 x := l.private l.private = nil if x == nil { // 如果没有，那么从全局池找 // Try to pop the head of the local shard. We prefer // the head over the tail for temporal locality of // reuse. x, _ = l.shared.popHead() if x == nil { x = p.getSlow(pid) } } runtime_procUnpin() //释放P，让其可以被抢占 if race.Enabled { race.Enable() if x != nil { race.Acquire(poolRaceAddr(x)) } } if x == nil \u0026\u0026 p.New != nil { x = p.New() } return x } // Put adds x to the pool. func (p *Pool) Put(x any) { if x == nil { return } if race.Enabled { if fastrandn(4) == 0 { // Randomly drop x on floor. return } race.ReleaseMerge(poolRaceAddr(x)) race.Disable() } l, _ := p.pin() // 老规矩，先禁止P被抢占 if l.private == nil { // 本地没有 则先放入本地 l.private = x } else { l.shared.pushHead(x) // 否则放入全局 } runtime_procUnpin() if race.Enabled { race.Enable() } } GC 其实很好理解，正好是一次二级缓冲模型，第一次gc会将local放入 victim，第二gc victim不为空才会真正清理，local不会参与gc\n","tags":["sync.pool"],"title":"sync.pool","type":"post"},{"authors":null,"categories":["Go"],"content":"cgo 一种go与c交互的技术 开启cgo 要求系统安装C/C++工具链，macos和linux(gcc 自带)，windows(mingw),并确保环境变量CGO_ENAVBLE=on,最后单个源码需要导入 import \u0026#34;C\u0026#34;\ncgo类型映射 C type Cgo type Go type char C.char byte signed char C.schar int8 unsigned char C.uchar uint8 short C.short int16 unsigned short C.ushort uint16 int C.int int32 unsigned int C.uint uint32 long C.long int32 unsigned long C.ulong uint32 long long int C.longlong int64 unsigned long long int C.ulonglong uint64 float C.float float32 double C.double double size_t C.size_t uint 函数指针 go引用c的函数指针比较特别\n官方给出的Example\n我这里给出另外一种,通过c wrap 这个函数指针成一个普通函数，然后go调用它\n//example.h typedef int (*add)(int a); int wrap_add(add f,int a){ if(f){ return add(a); } return 0; } struct、union、enum go通过C.struct_XXX 来访问c中的结构体，若结构体是 typedef 定义的则不需要 struct_ 前缀\n若c中结构体名称是go关键字，则需要加 _，如 _type\nunion在go中会被替换成等长byte数组\n//example.go /* union U1{ int a; long long int b; }; */ import \u0026#34;C\u0026#34; func Mock(){ var u = C.union_U1; // u的type为 [8]byte } 枚举在cgo中会被替换为一个常量，通过 C.Enum来访问\n函数调用 c call go: 通过编译指示 go:export来导出可供c调用的函数，但是参数及返回值都是c类型\ngo call c: 通过C.funcName来调用，但是参数及返回值都是c类型\n关于 \u0026lt;errno.h\u0026gt; 因为C语言不支持返回多个结果，因此\u0026lt;errno.h\u0026gt;标准库提供了一个errno宏用于返回错误状态。我们可以近似地将errno看着一个线程安全的全局变量，可以用于记录最近一次错误的状态码， CGO也针对\u0026lt;errno.h\u0026gt;标准库的errno宏做的特殊支持：在CGO调用C函数时如果有两个返回值，那么第二个返回值将对应errno错误状态。\n#include \u0026lt;errno.h\u0026gt; int div(int a, int b){ // 如果b=0,在go中将返回 (0,invalid argument) if(b == 0){ erron = EINVAL; return 0; } return a/b; } 编译和连接参数 Link ","date":1649203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649203200,"objectID":"1d6a4e2c7e0346fbadfc0de8c543a2e5","permalink":"https://domyson.github.io/post/lang/cgo/","publishdate":"2022-04-06T00:00:00Z","relpermalink":"/post/lang/cgo/","section":"post","summary":"cgo 一种go与c交互的技术 开启cgo 要求系统安装C/C++工具链，macos和linux(gcc 自带)，windows(mingw),并确保环境变量CGO_ENAVBLE=on,最后单个源码需要导入 import \"C\"\ncgo类型映射 C type Cgo type Go type char C.char byte signed char C.schar int8 unsigned char C.uchar uint8 short C.short int16 unsigned short C.ushort uint16 int C.int int32 unsigned int C.uint uint32 long C.long int32 unsigned long C.ulong uint32 long long int C.longlong int64 unsigned long long int C.ulonglong uint64 float C.float float32 double C.double double size_t C.size_t uint 函数指针 go引用c的函数指针比较特别\n官方给出的Example\n我这里给出另外一种,通过c wrap 这个函数指针成一个普通函数，然后go调用它\n","tags":null,"title":"Cgo","type":"post"},{"authors":null,"categories":["mysql"],"content":"聚集、非聚集、联合索引 A1: 聚集索引（主键索引）所有ROW都会按照主键索引进行排序\nA2: 非聚集索引即普通索引加上字段\nA3: 几个字段组成的索引\nA4: 聚集索引在物理上连续，非聚集索引在物理上不连续，但在逻辑上连续\nA5: 聚集索引影响物理存储顺序，而非聚集索引不影响\nA6: 聚集索引插入慢，查询快，非聚集索引反之\nA7: 索引是通过二叉树来描述的，聚集索引的子叶节点也是数据节点，而非聚集索引子叶节点仍是索引节点\n自增主键有哪些问题 A1: 分表分库的时候可能会出现重复情况（可使用uuid替代） A2: 产生表锁 A3: id耗尽 索引无效的情况 A1: 以%开头的LIKE语句，模糊匹配 A2: OR 前后字段未同时使用索引 A3: 数据类型隐式转换（varchar-\u0026gt;int) 查询优化 A1: 在WHERE和ORDER BY所涉及的列上加上索引 A2: SELECT避免使用*,SQL语句全部大写 A3: 避免WHERE对索引列上进行IS NULL判断，替换成IS NOT NULL A4: IN和NOT IN会导致全表扫描,替换为EXISTS或NOT EXISTS A5: 避免在索引上进行计算 A6: WHRER使用OR会放弃索引进而全表扫描 CHAR和VARCHAR的区别 A1: 存储和检索方式不同 A2: CHAR长度在创建时候指定(1~255),在存储时尾部全部填充空格 主键索引和唯一索引的区别 A1: 主键是一种约束 A2: 主键一定包含一个唯一索引，反之不成立 A3: 主键索引不允许包含空值，而唯一索引可以 A4: 一张表只能有一个主键索引，而唯一索引可以有多个 CPU飙升问题排查 A1: top命令观察mysqld A2: 若是，则show processlist查看是否是 SQL 的问题， A3: 若是，则检查执行计划是否准确，是否索引确实，数据是否太大 A4: kill上述线程，加索引，改内存，改SQL并重跑 A5: 若不是，可能是短时间有大量连接，可以限制最大连接数 如何创建索引 A1:\nCREATE INDEX indexName ON table; #创建普通索引 DROP INDEX indexName ON table; A2: 唯一索引和普通索引的区别是唯一索引值不允许重复\nCREATE UNIQUE INDEX indexName ON table; ALTER TABLE table ADD [UNIQUE|PRIMARY KEY] indexName; #修改表 # 直接在创建时指定 A3:\nSHOW INDEX from talbe; #显示表中的索引 索引 提高数据库表访问速度的一种数据结构，索引是一个文件，它需要占物理空间\n优缺点 + 加快数据查找速度，加快分组和排序的速度 + 占用空间，降低增删改的效率，因为索引是动态维护的 何时不用 + `where` 中用不到的字段 + 表记录较少 + 经常增删改 + 区分不高的字段 + 参与列计算的列 结构 hash表和b+树（默认） B+树 B+树更适应磁盘特性，相比于B树减少了I/O的读写次数，而B+树的非叶子节点只存key，因此单页可以存储更多的key，一次读入内存的需要查找的key就更多，因为数据只存在叶子节点上，查询效率为O(logN)， 而B树非叶子节点缓存了数据，只能通过中序遍历按序遍历，B+树叶子节点使用链表进行连接，所以遍历所有数据只需要遍历一边叶子节点，效率更高 虽然hash索引查找更快，但存储时时无序的，所以无法排序，并且不支持模糊查找，也不支持范围查找 分类 主键索引 唯一非空索引，列不允许重复\n组合索引 在多个字段上创建的索引，需要遵从最左前缀原则，即在查询条件中，只有使用了组合索引的第一个字段，索引才会被使用\n唯一索引 列值唯一但可以为空 sql alter table talbe_name add unique(field...) 普通索引 基本索引类型，没有唯一限制，允许为null\n```sql alter table table_name add index index_name(field...) ``` 全文索引 主要用来查询文本中的关键字，只能在 char,varchar,text上使用（innodb不支持全文索引） sql alter table table_name add fulltext(field) 原理 索引用来快速查询具有特定值的记录，如果没有索引，一般而言需要遍历整张表\n将创建了索引的列的内容进行排序\n对排序内容生成倒排表\n在倒排表内容上拼接数据地址链\n查询的时候先拿到倒排表，去除数据地址链，从而难道具体数据\n聚簇索引和非聚簇索引的区别 聚簇索引 将索引和数据放到了同一行，找到了索引也就找到了数据，无须进行回表查询操作\ninnodb 必然会有一个聚簇索引，通常是主键，若没有，则优先选择非空的唯一索引，若也没有，则会创建一个隐藏的 row_id 作为聚簇索引\n非聚簇索引 将索引和数据分开，找到索引后通过对应的地址找到数据行\n事务四大特性 原子性: 要么全部成功，要么全部失败\n一致性: 事务执行之前和执行之后都必须处于一致性状态\n隔离性: 与隔离级别有关\n持久性: 一旦提交，对数据库的改变就是永久的\n事务隔离级别 Read Commit 一个事务只能读取其他事务已提交的数据 重复读取\nRead Uncommit 所有事务可以读取其他事务未提交的数据，脏读\nRepeated Read 默认\nSerializable 串行化\n隔离级别所带来的问题 脏读 事务A读到了其他事务未提交的数据\n不可重复读 事务A读到了其他事务多次修改的数据，导致结果不一样\n幻读 事务A读到了其他事务修改的新数据，而在之前并没有这个数据\n重复读和幻读的区别在于前者是修改，后者是插入或者删除，sql标准中规定的RR级别不能消除幻读，但mysql的RR可以，原因在于间隙锁Gap lock\n|:-:|:-:|:-:|:-:| |隔离级别/问题|脏读|不可重复读|幻读| |RU|√|√|√| |RC|×|√|√| |RR|×|×|√| |SE|×|×|×|\nMVCC 锁 行锁 操作只锁住某一行，不能其它行有影响，它是一种排它锁（写锁）防止其他事务修改当前事务的操作数据，（innodb）默认锁机制 特点是开销大，加锁慢，会出现死锁，锁的颗粒最小，并发最高，冲突最低\n表锁 操作时会锁定整张表，（myisam）的默认机制\n特定是开销小，加锁快，不会出现死锁，锁的颗粒大，并发低，冲突高\n页锁 操作是锁住一页数据（16kb） 特定是介于行锁和表锁之间，会出现死锁，并发度一般\n读写锁 处理并发读读和写时，通常使用共享锁（读锁）和排他锁（写锁）\n读锁时共享的，相互之间不会阻塞，多个事务同一时刻能获取同一资源，但是不可修改数据\n写锁时排他的，其他事务不能获取这条数据的读锁和写锁\n加锁的sql\nselect * form table // 不加锁\nupdate/insert/delete // 加排他锁\nselect * form table where id // id如果是索引，就加排他锁\nselect * form table where id lock in share mode // 共享锁\n死锁 当多个事务以不同的顺序锁定资源，或者同时锁定同一个资源都会产生死锁\n解决思路 + innodb 可以自动检测死锁，使用一个事务回滚，另一个事务继续 + 设置超时等待参数 `innodb_local_wait_timeout` 如何避免 + 不同业务并发访问多个表时，编写相同的顺序访问 + 在事务中如果更新记录，使用排他锁 binlog redolog undolog relaylog binlog 事务提交的时候，一次性将事务中的sql语句（一个事物可能对应多个sql语句）按照一定的格式记录到binlog中。\n这里与redo log很明显的差异就是redo log并不一定是在事务提交的时候刷新到磁盘，redo log是在事务开始之后就开始逐步写入磁盘。\n因此对于事务的提交，即便是较大的事务，提交（commit）都是很快的，但是在开启了bin_log的情况下，对于较大事务的提交，可能会变得比较慢一些。\n用于复制，在主从复制中，从库利用主库上的binlog进行重播，实现主从同步。\n用于数据库的基于时间点的还原。\nredolog 事务开始之后就产生redo log，redo log的落盘并不是随着事务的提交才写入的，而是在事务的执行过程中，便开始写入redo log文件中。\n确保事务的持久性。redo日志记录事务执行后的状态，用来恢复未写入data file的已成功事务更新的数据。防止在发生故障的时间点，尚有脏页未写入磁盘，在重启mysql服务的时候，根据redo log进行重做，从而达到事务的持久性这一特性。\nundolog 事务开始之前，将当前是的版本生成undo log，undo 也会产生 redo 来保证undo log的可靠性\n保证数据的原子性，保存了事务发生之前的数据的一个版本，可以用于回滚，同时可以提供多版本并发控制下的读（MVCC），也即非锁定读\nrelaylog ","date":1649203200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1649203200,"objectID":"fd49b8e31f7c97c8d7b2a7150706b4d7","permalink":"https://domyson.github.io/post/mysql100%E9%97%AE/","publishdate":"2022-04-06T00:00:00Z","relpermalink":"/post/mysql100%E9%97%AE/","section":"post","summary":"聚集、非聚集、联合索引 A1: 聚集索引（主键索引）所有ROW都会按照主键索引进行排序\nA2: 非聚集索引即普通索引加上字段\nA3: 几个字段组成的索引\nA4: 聚集索引在物理上连续，非聚集索引在物理上不连续，但在逻辑上连续\nA5: 聚集索引影响物理存储顺序，而非聚集索引不影响\nA6: 聚集索引插入慢，查询快，非聚集索引反之\nA7: 索引是通过二叉树来描述的，聚集索引的子叶节点也是数据节点，而非聚集索引子叶节点仍是索引节点\n自增主键有哪些问题 A1: 分表分库的时候可能会出现重复情况（可使用uuid替代） A2: 产生表锁 A3: id耗尽 索引无效的情况 A1: 以%开头的LIKE语句，模糊匹配 A2: OR 前后字段未同时使用索引 A3: 数据类型隐式转换（varchar-\u003eint) 查询优化 A1: 在WHERE和ORDER BY所涉及的列上加上索引 A2: SELECT避免使用*,SQL语句全部大写 A3: 避免WHERE对索引列上进行IS NULL判断，替换成IS NOT NULL A4: IN和NOT IN会导致全表扫描,替换为EXISTS或NOT EXISTS A5: 避免在索引上进行计算 A6: WHRER使用OR会放弃索引进而全表扫描 CHAR和VARCHAR的区别 A1: 存储和检索方式不同 A2: CHAR长度在创建时候指定(1~255),在存储时尾部全部填充空格 主键索引和唯一索引的区别 A1: 主键是一种约束 A2: 主键一定包含一个唯一索引，反之不成立 A3: 主键索引不允许包含空值，而唯一索引可以 A4: 一张表只能有一个主键索引，而唯一索引可以有多个 CPU飙升问题排查 A1: top命令观察mysqld A2: 若是，则show processlist查看是否是 SQL 的问题， A3: 若是，则检查执行计划是否准确，是否索引确实，数据是否太大 A4: kill上述线程，加索引，改内存，改SQL并重跑 A5: 若不是，可能是短时间有大量连接，可以限制最大连接数 如何创建索引 A1:\n","tags":null,"title":"Mysql QA","type":"post"},{"authors":null,"categories":["go"],"content":"如何启用GC跟踪 GODEBUG=gctrace=1 go run *.go\n其中 gctrace=1 表示只针对这个进程进行GC追踪\n标记流程 go采用三色标记法，主要是为了提高并发度，这样扫描过程可以拆分为多个阶段，而不用一次扫描全部\n黑 根节点扫描完毕，子节点也扫描完毕\n灰 根节点扫描完毕，子节点未扫描\n白 未扫描\n扫描是从 .bss .data goroutine栈开始扫描，最终遍历整个堆上的对象树\n标记 mark 标记过程是一个广度优先的遍历过程，扫描节点，将节点的子节点推送到任务队列中，然后递归扫描子叶节点，直到所有工作队列被排空\nmark阶段会将白色对象标记，并推入队列中变为灰色\nmemory barrier 保障了代码描述中对内存的操作顺序，即不会在编译期被编译器进行调整，也不会在运行时被CPU的乱序执行所打乱\nwrite barrier 在应用进入 GC 标记阶段前的 stw 阶段，会将全局变量 runtime.writeBarrier.enabled 修改为 true，这时所有的堆上指针修改操作在修改之前便会额外调用 runtime.gcWriteBarrier\n由于GC和Go主程序并发执行，所以必须要在扫描时监控内存可能出现的状态改变，所以需要写屏障，所以需要暂停GO主程序（STW）\nhybrid wirte barrier (after go1.8) 改方式的基本思想是：对正在被覆盖的对象进行着色，且如果当时栈未扫描完成，则同样对指针进行着色\nGC流程 程序启动会为每个P分配一个 mark worker 来标记内存，负责为进入STW做前期工作\n起初认为所有 object 都被认定为白色 但栈，堆和全局变量的object被标记为灰色 GC会将灰色object标记为黑色，将灰色object所包含的所有指针所指向的地址都标记为灰色，递归这两个步骤，最终对象非黑即白，其中白色object即未被引用且可以被回收，如果object标记为no scan，则递归结束，标记为黑色\ntodo https://blog.csdn.net/asd1126163471/article/details/124113816\n","date":1645833600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1645833600,"objectID":"3fe4b7a746b66e442c64d0ec08a50b2e","permalink":"https://domyson.github.io/post/lang/gc/","publishdate":"2022-02-26T00:00:00Z","relpermalink":"/post/lang/gc/","section":"post","summary":"如何启用GC跟踪 GODEBUG=gctrace=1 go run *.go\n其中 gctrace=1 表示只针对这个进程进行GC追踪\n标记流程 go采用三色标记法，主要是为了提高并发度，这样扫描过程可以拆分为多个阶段，而不用一次扫描全部\n黑 根节点扫描完毕，子节点也扫描完毕\n灰 根节点扫描完毕，子节点未扫描\n白 未扫描\n扫描是从 .bss .data goroutine栈开始扫描，最终遍历整个堆上的对象树\n标记 mark 标记过程是一个广度优先的遍历过程，扫描节点，将节点的子节点推送到任务队列中，然后递归扫描子叶节点，直到所有工作队列被排空\nmark阶段会将白色对象标记，并推入队列中变为灰色\nmemory barrier 保障了代码描述中对内存的操作顺序，即不会在编译期被编译器进行调整，也不会在运行时被CPU的乱序执行所打乱\nwrite barrier 在应用进入 GC 标记阶段前的 stw 阶段，会将全局变量 runtime.writeBarrier.enabled 修改为 true，这时所有的堆上指针修改操作在修改之前便会额外调用 runtime.gcWriteBarrier\n由于GC和Go主程序并发执行，所以必须要在扫描时监控内存可能出现的状态改变，所以需要写屏障，所以需要暂停GO主程序（STW）\nhybrid wirte barrier (after go1.8) 改方式的基本思想是：对正在被覆盖的对象进行着色，且如果当时栈未扫描完成，则同样对指针进行着色\nGC流程 程序启动会为每个P分配一个 mark worker 来标记内存，负责为进入STW做前期工作\n起初认为所有 object 都被认定为白色 但栈，堆和全局变量的object被标记为灰色 GC会将灰色object标记为黑色，将灰色object所包含的所有指针所指向的地址都标记为灰色，递归这两个步骤，最终对象非黑即白，其中白色object即未被引用且可以被回收，如果object标记为no scan，则递归结束，标记为黑色\ntodo https://blog.csdn.net/asd1126163471/article/details/124113816\n","tags":["GC"],"title":"Go GC分析","type":"post"},{"authors":null,"categories":["linux"],"content":"什么是 Tcp 三次握手 tcp client发送连接请求报文，报文首部同步标记位 SYN=1 同时随机序列号 seq=x，此时 tcp client 进入 SYNC-SENT 状态的\ntcp server 若同意连接则确认报文为 ACK=1,SYN=1,ASK=x+1,seq=y 返回给客户端，并进入 SYNC_RCVD 状态\ntcp client 收到回复并确认 ACK 是否为1，seq 是否为 x+1,并返回报文 ACK=1,ASK=y+1,此时双方进入 ESTABLISHED 状态\n四次挥手 主动方发送报文FIN=1,seq=last+1并进入FIN_WAIT_1,此时报文不能携带任何数据\n被动方收到连接释放报文，并发送确认报文 ACK=1,ack=u+1,seq=v ，并进入 CLOSE_WAIT状态，但此时如果缓冲区存在未发送数据，那么需要继续发送（这也是 CLOSE_WAIT 持续的时长），主动方收到此条报文后进入 FIN_WAIT_2,因为还需要处理未发送数据\n上一步执行完毕，被动方发送 FIN=1,ack=w+1,seq=u+1 并进入 LAST-ACK 状态，而主动方收到此条报文后进入 TIME_WAIT （2msl maximum segment life），之后才会进入 CLOSED\n在主动方进入 CLOSED 之前，需要发送报文确认退出\n2MSL 1MSL保证主动方最后的 ACK 能到达对端，1MSL 确保 ACK 重传\n如何确保可靠性 三次握手，四次挥手确保连接和断开的可靠\n记录了哪些数据被接受，哪些未接收，序列号保证了消息的顺序性\nACK应答，超时重传，失序重传，丢弃重复数据，流量控制，拥塞控制\n重传机制 RTT，RTO Round-Trip Time 消息往返时间 Retransmission Timeout 超时重传\n快速重传 不以时间为驱动，而是以接收方返回信息触发\n滑动窗口 本质上是内核开辟了一个缓冲区，依据tcp头部的win(16bit) 来确认，其大小表示无需等待确认应答，可以发送或接收数据的最大值，在发送确认报文的时候同时告知对方\n发送窗口 分为四段，已发送已确认，已发送未确认，未发送但可发送，未发送但不可发送\n接收窗口 分为三段，已接收并确认，未接收但可以接收，未接收且不可接收\n拥塞机制 拥塞控制是作用于网络的，防止过多的数据包注入到网络中，避免出现网络负载过大的情况。它的目标主要是最大化利用网络上瓶颈链路的带宽。它跟流量控制又有什么区别呢？流量控制是作用于接收者的，根据接收端的实际接收能力控制发送速度，防止分组丢失\n发送方维护一个 cwnd 窗口，估算当前网络可以承载的数据量，它是动态的，只要没有出现阻塞就增大一些，若阻塞则减少一些\n拥塞算法 慢启动 连接建立完成后，先探测网络的拥塞程度,如果未出现丢包，没收到一个ACK，cwnd+1(MSS)，每一个RTT过后cwnd增加一倍，若出现丢包则减半\n拥塞避免 当cwnd超过慢启动阈值ssthresh时，进入拥塞避免，一般是64kb，即cwnd不再增加\n拥塞发生 当网络拥塞发生丢包时，存在两种情况: RTO超时重传，慢启动阈值减半，cwnd = 1，并重新进入慢启动。发送发收到3个重复的ACK时进入快速重传，cwnd=cwnd/2,ssthresh = cwnd,并进入快速恢复\n快速恢复 cwnd = ssthresh +3 ,重传丢失的的数据包，如果再收到重复的ACK，则 cwnd+1，当收到新的ACK后（即恢复正常）cwnd=ssthresh,并重新进入拥塞避免\n半连接 即tcp server 回复 ACK,SYN 后，这个连接被推入了SYN队列，即半连接队列，若 tcp client 确认并回复ACK后则会被推入Aceept队列，即全连接队列\n预防 SYN FLOOD 伪造不存在ip，发送大量的SYN报文，导致服务器无法收到正确的ACK报文，以至于半连接队列满载\nSYN PROXY 代理真实服务器的半连接队列\nSYN COOKIE 服务器拦截原始SYN报文，这个太硬核\n粘包和拆包 由于发送缓冲区的关系，以及读取缓冲区的关系，一般由业务层决定（固定长度，长度+消息，请求应答）\n","date":1631750400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1631750400,"objectID":"66b927596b1ff9075d141c9a93b86b71","permalink":"https://domyson.github.io/post/linux/tcp/","publishdate":"2021-09-16T00:00:00Z","relpermalink":"/post/linux/tcp/","section":"post","summary":"什么是 Tcp 三次握手 tcp client发送连接请求报文，报文首部同步标记位 SYN=1 同时随机序列号 seq=x，此时 tcp client 进入 SYNC-SENT 状态的\ntcp server 若同意连接则确认报文为 ACK=1,SYN=1,ASK=x+1,seq=y 返回给客户端，并进入 SYNC_RCVD 状态\ntcp client 收到回复并确认 ACK 是否为1，seq 是否为 x+1,并返回报文 ACK=1,ASK=y+1,此时双方进入 ESTABLISHED 状态\n四次挥手 主动方发送报文FIN=1,seq=last+1并进入FIN_WAIT_1,此时报文不能携带任何数据\n被动方收到连接释放报文，并发送确认报文 ACK=1,ack=u+1,seq=v ，并进入 CLOSE_WAIT状态，但此时如果缓冲区存在未发送数据，那么需要继续发送（这也是 CLOSE_WAIT 持续的时长），主动方收到此条报文后进入 FIN_WAIT_2,因为还需要处理未发送数据\n上一步执行完毕，被动方发送 FIN=1,ack=w+1,seq=u+1 并进入 LAST-ACK 状态，而主动方收到此条报文后进入 TIME_WAIT （2msl maximum segment life），之后才会进入 CLOSED\n在主动方进入 CLOSED 之前，需要发送报文确认退出\n2MSL 1MSL保证主动方最后的 ACK 能到达对端，1MSL 确保 ACK 重传\n如何确保可靠性 三次握手，四次挥手确保连接和断开的可靠\n记录了哪些数据被接受，哪些未接收，序列号保证了消息的顺序性\nACK应答，超时重传，失序重传，丢弃重复数据，流量控制，拥塞控制\n重传机制 RTT，RTO Round-Trip Time 消息往返时间 Retransmission Timeout 超时重传\n","tags":["tcp"],"title":"tcp协议","type":"post"},{"authors":null,"categories":["Go"],"content":" Golang 默认指针是类型安全的，但它有很多限制。Golang 还有非类型安全的指针，这就是 unsafe 包提供的 unsafe.Pointer。在某些情况下，它会使代码更高效，当然，也更危险。unsafe 包用于 Go 编译器，在编译阶段使用。从名字就可以看出来，它是不安全的，官方并不建议使用。Go 语言类型系统是为了安全和效率设计的，有时，安全会导致效率低下。unsafe 包绕过了 Go 的类型系统，达到直接操作内存的目的，使用它有一定的风险性。但是在某些场景下，使用 unsafe 包提供的函数会提升代码的效率，Go 源码中也是大量使用 unsafe 包。\nunsafe 包 //定义 type ArbitraryType int type Pointer *ArbitraryType //函数 func Sizeof(x AribitraryType) uintptr{} func Offsetof(x AribitraryType) uintptr{} func Alignof(x AribitraryType) uintptr{} 分析 Pointer : 指向任意类型，类似于 C 中的 void*。\nSizeof : 返回所传类型的大小，指针只返回指针的本身（x64 8byte x86 4byte），而不会返回所指向的内存大小。\nOffsetof : 返回 struct 成员在内存中的位置，相对于此结构体的头位置，所传参数必须是结构体成员。传入指针，或者结构体本身，会 error\nAlignof : 返回 M，M 是内存对齐时的倍数。\n任意指针都可以和 unsafe.Pointer 相互转换。\nuintptr 可以和 unsafe.Pointer 相互转换。\n综上，unsafe.Pointer 是不能进行指针运算的，只能先转为 uintptr 计算完再转回 unsafe.Pointer ,还有一点要注意的是， uintptr 并没有指针的语义，意思就是 uintptr 所指向的对象会被 gc。而 unsafe.Pointer 有指针语义，可以保护它所指向的对象在“有用”的时候不会被垃圾回收。\n注意 uintptr：只代表了一个地址的值，其本身是一个整形变量，那么意味着其表示地址的内存可能会被GC。\nunsafe.Poniter：本身指向一个确定内存的地址，相当于其它类型指针的一个抽象，那么其指向的内存将不会被GC。\n应用 bbuf\n获取 slice 的长度和容量 //runtime/slice.go type slice struct{ array unsafe.Pointer len int cap int } //而make时创造一个 slice 的结构体 func makeslice(et *_type,len,cap int) slice //那么 s := make([]int,10,20) //这一步网上教程有一个错误：直接加上8的偏移，这在x64机器上这个偏移将会是4 l := *(*int(unsafe.Pointer((uintptr(unsafe.Pointer(\u0026amp;s))+unsafe.Alignof(s))))) c := *(*int(unsafe.Pointer((uintptr(unsafe.Pointer(\u0026amp;s))+unsafe.Alignof(s)*2)))) string 和 slice 的转换 //高性能的做法是 zero-copy，那么共享底层 []byte 即可 //reflect/value.go type StringHeader struct { Data uintptr Len int } type SliceHeader struct { Data uintptr Len int Cap int } //所以 func String2Bytes(s string) []byte { strH := (*reflect.StringHeader)(unsafe.Pointer(\u0026amp;s)) bh := reflect.SliceHeader{ Data: strH.Data, Len: strH.Len, Cap: strH.Len, } return *(*[]byte)(unsafe.Pointer(\u0026amp;bh)) } func Bytes2String(b []byte) string { byteH := (*reflect.SliceHeader)(unsafe.Pointer(\u0026amp;b)) sh := reflect.StringHeader{ Data: byteH.Data, Len: byteH.Len, } return *(*string)(unsafe.Pointer(\u0026amp;sh)) } 总结 unsafe.Pointer 提供一定程度上的底层内存操作，本质上还是内存排列的关系，使用它能够提升一些类型转换速度，但需要对内存的比较熟悉。\n","date":1629849600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1629849600,"objectID":"9e61569abeb3d3739ea347be4b3e14e2","permalink":"https://domyson.github.io/post/lang/unsafe/","publishdate":"2021-08-25T00:00:00Z","relpermalink":"/post/lang/unsafe/","section":"post","summary":" Golang 默认指针是类型安全的，但它有很多限制。Golang 还有非类型安全的指针，这就是 unsafe 包提供的 unsafe.Pointer。在某些情况下，它会使代码更高效，当然，也更危险。unsafe 包用于 Go 编译器，在编译阶段使用。从名字就可以看出来，它是不安全的，官方并不建议使用。Go 语言类型系统是为了安全和效率设计的，有时，安全会导致效率低下。unsafe 包绕过了 Go 的类型系统，达到直接操作内存的目的，使用它有一定的风险性。但是在某些场景下，使用 unsafe 包提供的函数会提升代码的效率，Go 源码中也是大量使用 unsafe 包。\nunsafe 包 //定义 type ArbitraryType int type Pointer *ArbitraryType //函数 func Sizeof(x AribitraryType) uintptr{} func Offsetof(x AribitraryType) uintptr{} func Alignof(x AribitraryType) uintptr{} 分析 Pointer : 指向任意类型，类似于 C 中的 void*。\nSizeof : 返回所传类型的大小，指针只返回指针的本身（x64 8byte x86 4byte），而不会返回所指向的内存大小。\nOffsetof : 返回 struct 成员在内存中的位置，相对于此结构体的头位置，所传参数必须是结构体成员。传入指针，或者结构体本身，会 error\nAlignof : 返回 M，M 是内存对齐时的倍数。\n任意指针都可以和 unsafe.Pointer 相互转换。\nuintptr 可以和 unsafe.Pointer 相互转换。\n综上，unsafe.Pointer 是不能进行指针运算的，只能先转为 uintptr 计算完再转回 unsafe.Pointer ,还有一点要注意的是， uintptr 并没有指针的语义，意思就是 uintptr 所指向的对象会被 gc。而 unsafe.Pointer 有指针语义，可以保护它所指向的对象在“有用”的时候不会被垃圾回收。\n","tags":null,"title":"unsafe包","type":"post"},{"authors":null,"categories":[""],"content":"音频 短音频使用Wav，长音频使用mp3 纹理 Mipmap mipmap用于减少渲染的带宽压力，但会有额外的内存开销，一般而言UI是建议关闭的，3D模型看情况开启\nRead/Write 纹理尺寸 不同大小的纹理尺寸对内存的占用也是不同，依照项目的实际情况来决定Size\n格式 由于ETC、PVRTC等格式均为有损压缩，因此，当纹理色差范围跨度较大时，均不可避免地造成不同程度的“阶梯”状的色阶问题。因此，很多研发团队使用RGBA32/ARGB32格式来实现更好的效果。但是，这种做法将造成很大的内存占用\nETC1 不支持透明通道问题 可以通过 RGB24 + Alpha8 + Shader 的方式达到比较好的效果\nECT2，ASTC 但需要设备支持 OpenGL ES3.0\nLOD unity内置的一项技术，主要是根据目标离相机的距离来断定使用何种精度的模型，减少顶点数的绘制，但代价就是要牺牲部分内存\nOcclusion culling 遮挡剔除 遮挡剔除是用来消除躲在其他物件后面看不到的物件，这代表资源不会浪费在计算那些看不到的顶点上，进而提升性能\nbatching dynamic batching 将一些足够小的网格，在CPU上转换它们的顶点，将许多相似的顶点组合在一起，并一次性绘制它们。 无论静态还是动态合批都要求使用相同的材质，动态合批有以下限制：\n+ 如果GameObjects在Transform上包含镜像，则不会对其进行动态合批处理 + 使用多个pass的shader不会被动态合批处理 + 使用不同的Material实例会导致GameObjects不能一起批处理，即使它们基本相同。 + [官方25个不能动批的情况](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2FUnity-Technologies%2FBatchBreakingCause) static batching 静态合批是将静态（不移动）GameObjects组合成大网格，然后进行绘制。静态合批使用比较简单，PlayerSettings中开启static batching，然后对需要静态合批物体的Static打钩即可，unity会自动合并被标记为static的对象，前提它们共享相同的材质，并且不移动，被标记为static的物体不能在游戏中移动，旋转或缩放。但是静态批处理需要额外的内存来存储合并的几何体。注意如果多个GameObject在静态批处理之前共享相同的几何体，则会在编辑器或运行时为每个GameObject创建几何体的副本，这会增大内存的开销\nGPU Instancing 使用GPU Instancing可以一次渲染(render)相同网格的多个副本，仅使用少量DrawCalls。在渲染诸如建筑、树木、草等在场景中重复出现的事物时，GPU Instancing很有用。\n每次draw call，GPU Instancing只渲染相同(identical )的网格，但是每个实例(instance)可以有不同的参数(例如，color或scale)，以增加变化(variation)，减少重复的出现。\nGPU Instancing可以减少每个场景draw calls次数。这显著提升了渲染性能。\nPhysics Auto Simulation 根据项目实际需要是否开启物理模拟，默认是是开启的\nFixed Timestep 过小的值会操成计算量过大，过大的值可能造成部分机制异常(如卡墙，穿透等)，根据项目实际来确定\nMaximum Allowed Timestep 这里我们需要先知道物理系统本身的特性，即当游戏上一帧卡顿时，Unity会在当前帧非常靠前的阶段连续调用N次FixedUpdate.PhysicsFixedUpdate，Maximum Allowed Timestep的意义就在于单帧限制物理更新的次数，\nContact数量是否合理 减少不必要的物理碰撞检测，如盾牌和地面，或者当场景contact为0时，且存在物理消耗应当关闭 Auto Simulation\nAuto Sync Transforms\n勾选Auto Sync Transforms后，发生Physics Query时，Unity会将Rigidbody/Collider的Tranform变化同步到物理引擎，如Position，Scale等。另外勾选AutoSimulation时，Unity会在每次物理更新的时候自动同步一次Rigidbody和Collider，所以当关闭AutoSimulation后，如果项目中使用了射线检测或者NGUI，通常需要Auto Sync Transforms进行勾选，否则会发生射线检测结果不准确或者UI事件不响应的情况。\nRaycast 减少射线检测 Unity 托管内存 用户代码分配的内存本质上在 IL2CPP 构建的 VM 的托管内存(Managed Memory)上，所以用户代码分配遵从于这个 VM 的分配方式。\nIL2CPP 采用的是 Boehm 回收算法,这算法的缺陷是 不分代，不压缩，虽然提高了效率，但由于用户申请内存的不确定性，容易造成内存碎片，不利于此块的内存重使用。\n内存以 Block 来管理，当一个 Block 6次GC没有被访问，才会返回给 OS。\nZombie Memory,由于用户不主动释放，但实际没有使用。那么这块内存将不会被回收。\n对于一个物体，应该是 Destory 而不是置为 Null。\n下一代采用 渐进式GC（分帧GC，使CPU峰值更平滑），可以手动开关。\n浅谈Unity内存管理\n提升加载场景速度 Application.backgroundLoadingPriority为High Application.backgroundLoadingPriority这个API会限制主线程的集成的时间，默认设置是ThreadPriority.BelowNormal，也就是每一帧执行主线程集成的操作耗时不能超过4毫秒，这将会导致每一帧剩余的时间用于等待或者渲染，而这些等待和渲染的时间都是无意义的耗时。如果把这个设置改为ThreadPriority.High，那么每一帧执行主线程集成的操作耗时可以增加到50毫秒，大大减少了所需要的帧数。\n分析工具 UnityProfiler，UWA\n","date":1602288000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1602288000,"objectID":"20ef417284c3078174e889160e4f7268","permalink":"https://domyson.github.io/post/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","publishdate":"2020-10-10T00:00:00Z","relpermalink":"/post/%E6%80%A7%E8%83%BD%E4%BC%98%E5%8C%96/","section":"post","summary":"音频 短音频使用Wav，长音频使用mp3 纹理 Mipmap mipmap用于减少渲染的带宽压力，但会有额外的内存开销，一般而言UI是建议关闭的，3D模型看情况开启\nRead/Write 纹理尺寸 不同大小的纹理尺寸对内存的占用也是不同，依照项目的实际情况来决定Size\n格式 由于ETC、PVRTC等格式均为有损压缩，因此，当纹理色差范围跨度较大时，均不可避免地造成不同程度的“阶梯”状的色阶问题。因此，很多研发团队使用RGBA32/ARGB32格式来实现更好的效果。但是，这种做法将造成很大的内存占用\nETC1 不支持透明通道问题 可以通过 RGB24 + Alpha8 + Shader 的方式达到比较好的效果\nECT2，ASTC 但需要设备支持 OpenGL ES3.0\nLOD unity内置的一项技术，主要是根据目标离相机的距离来断定使用何种精度的模型，减少顶点数的绘制，但代价就是要牺牲部分内存\nOcclusion culling 遮挡剔除 遮挡剔除是用来消除躲在其他物件后面看不到的物件，这代表资源不会浪费在计算那些看不到的顶点上，进而提升性能\nbatching dynamic batching 将一些足够小的网格，在CPU上转换它们的顶点，将许多相似的顶点组合在一起，并一次性绘制它们。 无论静态还是动态合批都要求使用相同的材质，动态合批有以下限制：\n+ 如果GameObjects在Transform上包含镜像，则不会对其进行动态合批处理 + 使用多个pass的shader不会被动态合批处理 + 使用不同的Material实例会导致GameObjects不能一起批处理，即使它们基本相同。 + [官方25个不能动批的情况](https://links.jianshu.com/go?to=https%3A%2F%2Fgithub.com%2FUnity-Technologies%2FBatchBreakingCause) static batching 静态合批是将静态（不移动）GameObjects组合成大网格，然后进行绘制。静态合批使用比较简单，PlayerSettings中开启static batching，然后对需要静态合批物体的Static打钩即可，unity会自动合并被标记为static的对象，前提它们共享相同的材质，并且不移动，被标记为static的物体不能在游戏中移动，旋转或缩放。但是静态批处理需要额外的内存来存储合并的几何体。注意如果多个GameObject在静态批处理之前共享相同的几何体，则会在编辑器或运行时为每个GameObject创建几何体的副本，这会增大内存的开销\nGPU Instancing 使用GPU Instancing可以一次渲染(render)相同网格的多个副本，仅使用少量DrawCalls。在渲染诸如建筑、树木、草等在场景中重复出现的事物时，GPU Instancing很有用。\n每次draw call，GPU Instancing只渲染相同(identical )的网格，但是每个实例(instance)可以有不同的参数(例如，color或scale)，以增加变化(variation)，减少重复的出现。\nGPU Instancing可以减少每个场景draw calls次数。这显著提升了渲染性能。\nPhysics Auto Simulation 根据项目实际需要是否开启物理模拟，默认是是开启的\nFixed Timestep 过小的值会操成计算量过大，过大的值可能造成部分机制异常(如卡墙，穿透等)，根据项目实际来确定\nMaximum Allowed Timestep 这里我们需要先知道物理系统本身的特性，即当游戏上一帧卡顿时，Unity会在当前帧非常靠前的阶段连续调用N次FixedUpdate.PhysicsFixedUpdate，Maximum Allowed Timestep的意义就在于单帧限制物理更新的次数，\n","tags":[""],"title":"Unity性能优化方案","type":"post"},{"authors":null,"categories":["net"],"content":"简介 传输层安全性协议（Transport Layer Security），及其前身 SSL3.0 之后安全套接层（Secure Sockets Layer，缩写作SSL）是一种安全协议，目的是为互联网通信提供安全及数据完整性保障。SSL包含记录层（Record Layer）和传输层，记录层协议确定传输层数据的封装格式。传输层安全协议使用X.509认证，之后利用RSA 加密演算来对通信方做身份认证，之后交换对称密钥作为会谈密钥（Session key）。这个会谈密钥是用来将通信两方交换的数据做加密，保证两个应用间通信的保密性和可靠性，使客户与服务器应用之间的通信不被攻击者窃听。\n作用 安全传输层协议（TLS）用于在两个通信应用程序之间提供保密性和数据完整性。\n协议由两层组成： TLS 记录协议（TLS Record）和 TLS 握手协议（TLS Handshake）。\nTLS协议的优势是与高层的应用层协议（如HTTP、FTP、Telnet等）无耦合。应用层协议能透明地运行在TLS协议之上，由TLS协议进行创建加密通道需要的协商和认证。应用层协议传送的数据在通过TLS协议时都会被加密，从而保证通信的私密性。\n连接过程 当客户端连接到支持TLS协议的服务器要求创建安全连接并列出了受支持的密码组合（加密密码算法和加密哈希函数），握手开始。\n服务器从该列表中决定加密和散列函数，并通知客户端。\n服务器发回其数字证书，此证书通常包含服务器的名称、受信任的证书颁发机构（CA）和服务器的公钥。 客户端确认其颁发的证书的有效性。\n为了生成会话密钥用于安全连接，客户端使用服务器的公钥加密随机生成的密钥，并将其发送到服务器，只有服务器才能使用自己的私钥解密。\n利用随机数，双方生成用于加密和解密的对称密钥。这就是TLS协议的握手，握手完毕后的连接是安全的，直到连接（被）关闭。如果上述任何一个步骤失败，TLS握手过程就会失败，并且断开所有的连接。\nTLS协议 https 本身基于 http 传输，但是信息通过了 tls 协议加密。\ntls 协议位于传输层之上，应用层之下。首次进行 tls 1.3 协议传输需要一个 RTT\ntls 可以使用对称加密和非对称加密。\n握手过程 客户端发送一个随机值以及需要的协议和加密方式。\n服务端收到客户端的随机值，自己也产生一个随机值，并根据客户端需求的协议和加密方式来使用对应的方式，并且发送自己的证书（如果需要验证客户端证书需要说明）。\n客户端收到服务端的证书并验证是否有效，验证通过会再生成一个随机值，通过服务端证书的公钥去加密这个随机值并发送给服务端，如果服务端需要验证客户端证书的话会附带证书。\n服务端收到加密过的随机值并使用私钥解密获得第三个随机值，这时候两端都拥有了三个随机值，可以通过这三个随机值按照之前约定的加密方式生成密钥，接下来的通信就可以通过该密钥来加密解密。\n之后通过此非对称加密传输的对称加密的密钥来进行正式通讯。\n","date":1581206400,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1581206400,"objectID":"968b9f2952f51eaf1177aaf17f875997","permalink":"https://domyson.github.io/post/linux/tls/","publishdate":"2020-02-09T00:00:00Z","relpermalink":"/post/linux/tls/","section":"post","summary":"简介 传输层安全性协议（Transport Layer Security），及其前身 SSL3.0 之后安全套接层（Secure Sockets Layer，缩写作SSL）是一种安全协议，目的是为互联网通信提供安全及数据完整性保障。SSL包含记录层（Record Layer）和传输层，记录层协议确定传输层数据的封装格式。传输层安全协议使用X.509认证，之后利用RSA 加密演算来对通信方做身份认证，之后交换对称密钥作为会谈密钥（Session key）。这个会谈密钥是用来将通信两方交换的数据做加密，保证两个应用间通信的保密性和可靠性，使客户与服务器应用之间的通信不被攻击者窃听。\n作用 安全传输层协议（TLS）用于在两个通信应用程序之间提供保密性和数据完整性。\n协议由两层组成： TLS 记录协议（TLS Record）和 TLS 握手协议（TLS Handshake）。\nTLS协议的优势是与高层的应用层协议（如HTTP、FTP、Telnet等）无耦合。应用层协议能透明地运行在TLS协议之上，由TLS协议进行创建加密通道需要的协商和认证。应用层协议传送的数据在通过TLS协议时都会被加密，从而保证通信的私密性。\n连接过程 当客户端连接到支持TLS协议的服务器要求创建安全连接并列出了受支持的密码组合（加密密码算法和加密哈希函数），握手开始。\n服务器从该列表中决定加密和散列函数，并通知客户端。\n服务器发回其数字证书，此证书通常包含服务器的名称、受信任的证书颁发机构（CA）和服务器的公钥。 客户端确认其颁发的证书的有效性。\n为了生成会话密钥用于安全连接，客户端使用服务器的公钥加密随机生成的密钥，并将其发送到服务器，只有服务器才能使用自己的私钥解密。\n利用随机数，双方生成用于加密和解密的对称密钥。这就是TLS协议的握手，握手完毕后的连接是安全的，直到连接（被）关闭。如果上述任何一个步骤失败，TLS握手过程就会失败，并且断开所有的连接。\nTLS协议 https 本身基于 http 传输，但是信息通过了 tls 协议加密。\ntls 协议位于传输层之上，应用层之下。首次进行 tls 1.3 协议传输需要一个 RTT\ntls 可以使用对称加密和非对称加密。\n握手过程 客户端发送一个随机值以及需要的协议和加密方式。\n服务端收到客户端的随机值，自己也产生一个随机值，并根据客户端需求的协议和加密方式来使用对应的方式，并且发送自己的证书（如果需要验证客户端证书需要说明）。\n客户端收到服务端的证书并验证是否有效，验证通过会再生成一个随机值，通过服务端证书的公钥去加密这个随机值并发送给服务端，如果服务端需要验证客户端证书的话会附带证书。\n服务端收到加密过的随机值并使用私钥解密获得第三个随机值，这时候两端都拥有了三个随机值，可以通过这三个随机值按照之前约定的加密方式生成密钥，接下来的通信就可以通过该密钥来加密解密。\n之后通过此非对称加密传输的对称加密的密钥来进行正式通讯。\n","tags":["TLS"],"title":"TLS","type":"post"},{"authors":null,"categories":["linux"],"content":"进程状态 TASK_RUNNING TASK_INTERRUPTIBLE TASK_UNINTERRUPTIBLE TASK_TRACED TASK_STOPPED ","date":1577232000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1577232000,"objectID":"c26d5a74e9ea203792ed4fb057f988f4","permalink":"https://domyson.github.io/post/linux/process/","publishdate":"2019-12-25T00:00:00Z","relpermalink":"/post/linux/process/","section":"post","summary":"进程状态 TASK_RUNNING TASK_INTERRUPTIBLE TASK_UNINTERRUPTIBLE TASK_TRACED TASK_STOPPED ","tags":null,"title":"process","type":"post"},{"authors":null,"categories":["others"],"content":"简介 Protocol Buffers，是Google公司开发的一种数据描述语言，类似于XML能够将结构化数据序列化，可用于数据存储、通信协议等方面。本文只介绍 syntax = proto3 的协议语法。\n标准类型对照 .proto 注释 C++ Python Go C# double 定长编码 double float float64 double float 定长编码 float float float32 float int32 变长编码,负数编码效率低，可使用sint32 int32 int int32 int int64 变长编码,负数编码效率低，可使用sint64 int64 int/long int64 long uint32 变长编码 uint32 int/long uint32 uint uint64 变长编码 uint64 int/long unit64 ulong sint32 变长编码，对负数编码比int32更有效率 int32 int int32 int sint64 变长编码，对负数编码比int64更有效率 int64 int/long int64 long fixed32 总是4字节，如果值大于2^28比uint32更有效率 uint32 int/long uint64 ulong fixed64 总是8字节，如果值大于2^56比uint64更有效率 uint64 int/long uint64 ulong bool 1或0的变长编码 bool boolean bool bool string 必须是UTF-8编码 string str/unicode string string bytes 可包含任意的字节顺序 string str []byte ByteString 定义消息类型 Example synatx = \u0026#34;proto3\u0026#34;; package Pb; message Request{ string xxx = 1; int64 yyy = 2; float zzz = 3; double ppp = 4; } 第一行指定使用 proto3 语法，如果不指明，则默认使用 proto2 语法，这一行 不允许空白字符和注释\n第二行指明隶属于哪个包，在 go 中即为包名，在 csharp 中为命名空间\n使用 // 来注释\n指定标签 每一个字段都定义了一个唯一的 数值标签，这些唯一的数值标签用来标识 二进制消息 中你所定义的字段，一旦定义了编译后就无法修改。需要特别提醒的是标签 1–15 标识的字段编码仅占用 1 个字节（包括字段类型和标识标签）。 数值标签 16–2047 标识的字段编码占用 2 个字节。因此，你应该将标签 1–15 留给那些在你的消息类型中使用频率高的字段。记得预留一些空间（标签 1–15）给将来可能添加的高频率字段。\n字段规则 单数：该字段可以出现0或1次\n可重复 repeated：改字段可以重复任意次数，可以通过 [packed=true] 来申明更高效的编码：repeated int32 samples = 1 [packed=true];\n消息嵌套 在一个消息结构内部定义另外一个消息结构\nmessage Response{ //消息嵌套，可以无限嵌套 message Result{ string url = 1; //Field标签必须从1开始 string title =2; repeated string snippets = 3; } repeated Result results = 1; } message OtherResponse{ //外部使用内嵌消息 Response.Result result =1; } 保留字段 略\n默认值 string默认值为空字符串。\nbytes型默认值是空字节。\nbool型默认值为 false。\n数值类型默认值位 0。\nenum默认值是第一个枚举元素，它必须为 0。\nmessage类型字段默认值为 null。\n默认值字段是不会被序列化。\n枚举 message Request{ string url = 1; int number = 2; enum Corpus{ None = 0; //枚举标签第一个必须为0 Image=1; Viedo=2; } Corpus corpus = 4; } 导入其它 Protobuf import \u0026#34;proj/other.proto\u0026#34; //导入其他proto文件 import public \u0026#34;other.proto\u0026#34; //如果声明为public，那么other.proto导入的其他包也可以被引用 Map map\u0026lt;key,val\u0026gt; mapping = 1; //不能使用 repeated 修饰 //等效于 message Entry{ key_type key = 1; val_type val = 2; } repeated Entry entry = 1; key 只能是除 bytes \u0026amp; float、float64 以外的任意类型。key \u0026amp; val 也可以是自定义类型.\nRPC 服务接口类型 syntax=\u0026#34;proto3\u0026#34;; message SearchRequest{ } message SearchResponse{ } service SearchService { //rpc接口函数是Search //参数是SearchRequest，返回SearchResponse Search (SearchRequest) returns (SearchResponse); } ","date":1557705600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557705600,"objectID":"b99240a73657dbea9623ff67ff1a5f61","permalink":"https://domyson.github.io/post/protobuf/","publishdate":"2019-05-13T00:00:00Z","relpermalink":"/post/protobuf/","section":"post","summary":"简介 Protocol Buffers，是Google公司开发的一种数据描述语言，类似于XML能够将结构化数据序列化，可用于数据存储、通信协议等方面。本文只介绍 syntax = proto3 的协议语法。\n标准类型对照 .proto 注释 C++ Python Go C# double 定长编码 double float float64 double float 定长编码 float float float32 float int32 变长编码,负数编码效率低，可使用sint32 int32 int int32 int int64 变长编码,负数编码效率低，可使用sint64 int64 int/long int64 long uint32 变长编码 uint32 int/long uint32 uint uint64 变长编码 uint64 int/long unit64 ulong sint32 变长编码，对负数编码比int32更有效率 int32 int int32 int sint64 变长编码，对负数编码比int64更有效率 int64 int/long int64 long fixed32 总是4字节，如果值大于2^28比uint32更有效率 uint32 int/long uint64 ulong fixed64 总是8字节，如果值大于2^56比uint64更有效率 uint64 int/long uint64 ulong bool 1或0的变长编码 bool boolean bool bool string 必须是UTF-8编码 string str/unicode string string bytes 可包含任意的字节顺序 string str []byte ByteString ","tags":[""],"title":"Protobuf3","type":"post"},{"authors":null,"categories":["Go"],"content":"栈 一个 os 线程会有一个给固定大小的内存块（一般是 2MB），用来存储当前线程中调用或挂起函数的内部变量，固定大小的栈对于复杂和深层次递归是不够的，而 Goroutine 会以一个很小的栈（2KB）开始其生命周期，这个栈会动态伸缩，最大能到达 1GB（32位系统是 250M）\n调度方式 os 线程由操作系统内核调用，每过一定时间（毫秒），硬件计时器会中断处理器，并调用一个名为 scheduler 的内建函数，这个函数会挂起当前执行的线程并保存内存中它的寄存器内存，然后检查线程列表并决定下一次执行哪个线程，并从内存中恢复该线程的寄存器信息，恢复该线程的线程并执行，这就是上下文切换，增加了 CPU 的运行周期。而 Go 的 runtime 包含了自身的调度器，和 os 线程不同是，Goroutine 属于用户级线程由语言支持，调度由语言支持，所有开销会减少很多（相比于内核上下文切换）。\nGo的调度器（Scheduler） g 代表一个 goroutine，它包含：表示 goroutine 栈的一些字段，指示当前 goroutine 的状态，指示当前运行到的指令地址，也就是 PC 值。\nm 表示内核线程，包含正在运行的 goroutine 等字段。\np 代表一个虚拟的 Processor，它维护一个处于 Runnable 状态的 g 队列，m 需要获得 p 才能运行 g。\n还有一个核心的结构体：sched，它总览全局。\nRuntime 起始时会启动一些 G：垃圾回收的 G，执行调度的 G，运行用户代码的 G；并且会创建一个 M 用来开始 G 的运行。随着时间的推移，更多的 G 会被创建出来，更多的 M 也会被创建出来。\n它是运行在用户态的，\n它维护有存储M和G的队列以及调度器的一些状态信息等，并让每个 Goroutine 有机会运行\nM 每次取 P 中的队列是没有上下文切换开销的\nM ：代表 os（内核）线程\nOS线程抽象，代表着真正执行计算的资源，在绑定有效的P后，进入schedule循环；而schedule循环的机制大致是从Global队列、P的Local队列以及wait队列中获取G，切换到G的执行栈上并执行G的函数，调用goexit做清理工作并回到M，如此反复。M并不保留G状态，这是G可以跨M调度的基础，M的数量是不定的，由Go Runtime调整，为了防止创建过多OS线程导致系统调度不过来，目前默认最大限制为10000个。\nP ：代表逻辑处理器\nProcessor，表示逻辑处理器， 对G来说，P相当于CPU核（伪核，真正的执行体还是M所关联的内核线程），G只有绑定到P(在P的local runq中)才能被调度。对M来说，P提供了相关的执行环境(Context)，如内存分配状态(mcache)，任务队列(G)等，P的数量决定了系统内最大可并行的G的数量（前提：物理CPU核数 \u0026gt;= P的数量），P的数量由用户设置的GOMAXPROCS决定，但是不论GOMAXPROCS设置为多大，P的数量最大为256。\nP 维护了一个 local goroutines 队列 何时触发调度 由于 Go 语言是协作式的调度，不会像线程那样，在时间片用完后，由 CPU 中断任务强行将其调度走。对于 Go 语言中运行时间过长的 goroutine，Go scheduler 有一个后台线程在持续监控，一旦发现 goroutine 运行超过 10 ms，会设置 goroutine 的 “抢占标志位”，之后调度器会处理。\nsyscall select-case I/O（包括网络和文件） Gosched()函数调用 go func(){…}() GC时 同步互斥操作时 Goroutine Goroutine 可以看作对 thread 加的一层抽象，它更轻量级，可以单独执行。因为有了这层抽象，Gopher 不会直接面对 thread\n创建一个 goroutine 的栈内存消耗为 2 KB，在运行过程中，如果栈空间不够用，会自动进行扩容\nG 分为三种状态\nWaiting：表示被暂停了，需要等待一些事件发生才能继续，可能是因为 syscall,channel 或者互斥调用。\nRunnable：就绪状态，只要给 M 就可以运行\nRunning：运行状态。goroutine 在 M 上执行指令\n每个Goroutine对应一个G结构体，G存储Goroutine的运行堆栈、状态以及任务函数，可重用。G并非执行体，每个G需要绑定到P才能被调度执行。\n在同一时刻，一个线程上只能跑一个 goroutine。当 goroutine 发生阻塞（例如上篇文章提到的向一个 channel 发送数据，被阻塞）时，runtime 会把当前 goroutine 调度走，让其他 goroutine 有执行的机会\n异常捕获 当启动多个 goroutine 时，如果其中一个 goroutine 异常了，并且我们并没有对进行异常处理，那么整个程序都会终止，所以最好每个 goroutine 所运行的函数都做异常处理，异常处理采用 recover\ngo func(){ defer func(){ if err := recover();err != nil{ //TODO } } //Code... panic(\u0026#34;exit\u0026#34;) } 注意 recover 只能在 defer 的匿名函数中调用\nrecover 能捕获panic传入的错误，来保证 goroutine 是否继续执行还是正常退出\n如何同步 某些情况是主线程退出，但一部分 goroutine 还未执行完毕\n通过 sync.WaitGroup 来保证所有 goroutine 执行完成\n通过 channnel 来保证所有 goroutine 执行完成\nGC 因为 GC 操作是使用自己的一组 Goroutine 来执行的，这些 Goroutine 需要一个 M 来运行。所以 GC 会导致调度混乱。\n但是，因为调度器是知道 Goroutine 要做什么的，所以它可以做出明智的决策。其中一个明智的决策是，在 GC 过程中，暂停那些需要访问堆空间的 Goroutine（Stop The World），运行那些不需要访问堆空间的。\n思考 大部分goroutine使用都是在网络层，这部分goroutine 我称为 i/o 协程,但对于高并发而言，gorotuine 也会导致内存过高，\n而关于goroutine的调度问题，除了上述所说，网络底层是通过 i/o multiplex 事件来触发调度的,虽然 1.16 之后支持了抢占式调度，但错误的使用并不会提高性能，反而会降低.\n我们通过一组数据来证明它\n1 thread epoll Test Duration 10.1192694s: 1000 connections,fail: 0 Delay: Avg Max Stdev 23.074671ms 226.0378ms 23.074671ms Request/Sec: 17.60K/s Written/Sec: 17.18M/s Receive/Sec: 17.18M/s TotalWritten: 173.89M TotalReceive: 173.89M 4 thread epoll Test Duration 10.1532731s: 1000 connections,fail: 0 Delay: Avg Max Stdev 14.70811ms 295.5518ms 14.30601ms Request/Sec: 17.16K/s Written/Sec: 16.76M/s Receive/Sec: 16.76M/s TotalWritten: 170.12M TotalReceive: 170.12M standard go Test Duration 10.1377697s: 1000 connections,fail: 0 Delay: Avg Max Stdev 14.855782ms 276.5472ms14.855782ms Request/Sec: 17.22K/s Written/Sec: 16.82M/s Receive/Sec: 16.82M/s TotalWritten: 170.48M TotalReceive: 170.48M 从吞吐量可以看出，单 epoll 略高于其他方式，但综合数据同步以及内存使用来看，显然单线程 epoll 更适合\n总结 goroutine 虽然减少了心智负担，但它牺牲了一些性能，所以我个人认为，goroutine更适合成为一个库，而非语言标准。\n","date":1557619200,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1557619200,"objectID":"543697ee92c871c8f78f7cbb909d3c14","permalink":"https://domyson.github.io/post/lang/goroutine/","publishdate":"2019-05-12T00:00:00Z","relpermalink":"/post/lang/goroutine/","section":"post","summary":"栈 一个 os 线程会有一个给固定大小的内存块（一般是 2MB），用来存储当前线程中调用或挂起函数的内部变量，固定大小的栈对于复杂和深层次递归是不够的，而 Goroutine 会以一个很小的栈（2KB）开始其生命周期，这个栈会动态伸缩，最大能到达 1GB（32位系统是 250M）\n调度方式 os 线程由操作系统内核调用，每过一定时间（毫秒），硬件计时器会中断处理器，并调用一个名为 scheduler 的内建函数，这个函数会挂起当前执行的线程并保存内存中它的寄存器内存，然后检查线程列表并决定下一次执行哪个线程，并从内存中恢复该线程的寄存器信息，恢复该线程的线程并执行，这就是上下文切换，增加了 CPU 的运行周期。而 Go 的 runtime 包含了自身的调度器，和 os 线程不同是，Goroutine 属于用户级线程由语言支持，调度由语言支持，所有开销会减少很多（相比于内核上下文切换）。\n","tags":["goroutine"],"title":"Go协程的思考","type":"post"},{"authors":null,"categories":["cloud native"],"content":"什么是docker Docker 是一个开源的容器引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者和系统管理员在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括 VMs（虚拟机）、bare metal、OpenStack 集群、云端、数据中心和其他的基础应用平台。容器是完全使用沙箱机制，相互之间不会有任何接口。\n有什么优势 轻量，在一台机器上运行的多个Docker容器可以共享这台机器的操作系统内核；它们能够迅速启动，只需占用很少的计算和内存资源。镜像是通过文件系统层进行构造的，并共享一些公共文件。这样就能尽量降低磁盘用量，并能更快地下载镜像。\n标准，Docker 容器基于开放式标准，能够在所有主流Linux版本、Microsoft Windows以及包括VM、裸机服务器和云在内的任何基础设施上运行。\n安全，Docker 赋予应用的隔离性不仅限于彼此隔离，还独立于底层的基础设施。Docker默认提供最强的隔离，因此应用出现问题，也只是单个容器的问题，而不会波及到整台机器。\n一次发布，到处使用\nDocker和虚拟机 容器和虚拟机具有相似的资源隔离和分配优势，但功能有所不同，因为容器虚拟化的是操作系统，而不是硬件，因此容器更容易移植，效率也更高。\n传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。\n特性 容器 虚拟机 启动 秒级 分钟级 硬盘 MB GB 性能 接近原生 弱于原生 支持量 单机上千 单机几十左右 容器是一个应用层抽象，用于将代码和依赖资源打包在一起。 多个容器可以在同一台机器上运行，共享操作系统内核，但各自作为独立的进程在用户空间中运行 。与虚拟机相比， 容器占用的空间较少（容器镜像大小通常只有几十兆），瞬间就能完成启动。\n虚拟机（VM）是一个物理硬件层抽象，用于将一台服务器变成多台服务器。 管理程序允许多个VM在一台机器上运行。每个VM都包含一整套操作系统、一个或多个应用、必要的二进制文件和库资源，因此占用大量空间。而且VM启动也十分缓慢 。\n虚拟机更擅长于彻底隔离整个运行环境。例如，云服务提供商通常采用虚拟机技术隔离不同的用户。而 Docker 通常用于隔离不同的应用 ，例如前端，后端以及数据库。\nDocker基本组成 镜像 （Image）\n容器（Container）\n仓库（Repository）\n镜像（Image）—— 一个特殊的文件系统 操作系统分为内核和用户空间。对于Linux而言，内核启动后，会挂载root文件系统为其提供用户空间支持。而Docker镜像（Image），就相当于是一个root文件系统。Docker镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。 镜像不包含任何动态数据，其内容在构建之后也不会被改变。Docker设计时，就充分利用Union FS的技术，将其设计为分层存储的架构。 镜像实际是由多层文件系统联合组成。镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。\n容器（Container）—— 镜像运行时的实体 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等 。容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的命名空间。前面讲过镜像使用的是分层存储，容器也是如此。容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。按照Docker最佳实践的要求，容器不应该向其存储层内写入任何数据 ，容器存储层要保持无状态化。所有的文件写入操作，都应该使用数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此， 使用数据卷后，容器可以随意删除、重新run，数据却不会丢失。\n仓库（Repository）—— 集中存放镜像文件的地方 镜像构建完成后，可以很容易的在当前宿主上运行，但是， 如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry就是这样的服务。一个Docker Registry中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。所以说：镜像仓库是Docker用来集中存放镜像文件的地方类似于我们之前常用的代码仓库。通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本 。我们可以通过\u0026lt;仓库名\u0026gt;:\u0026lt;标签\u0026gt;的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以latest作为默认标签。\nDocker Registry公开服务和私有Docker Registry Docker Registry公开服务是开放给用户使用、允许用户管理镜像的Registry服务。一般这类公开服务允许用户免费上传、下载公开的镜像，并可能提供收费服务供用户管理私有镜像。最常使用的Registry公开服务是官方的Docker Hub ，这也是默认的Registry，并拥有大量的高质量的官方镜像，网址为：hub.docker.com/ 。在国内访问Docker Hub可能会比较慢国内也有一些云服务商提供类似于Docker Hub的公开服务。除了使用公开服务外，用户还可以在本地搭建私有Docker Registry 。Docker官方提供了Docker Registry镜像，可以直接使用做为私有Registry服务。开源的Docker Registry镜像只提供了Docker Registry API的服务端实现，足以支持Docker命令，不影响使用。但不包含图形界面，以及镜像维护、用户管理、访问控制等高级功能。\nImage 查看、拉取、删除 搜索镜像\ndocker search name[:tag]\n拉取镜像,若不指定tag则默认拉取latest\ndocker pull name[:tag]\n查看本地所有镜像\ndocker images\n删除镜像，可以多个删除\ndocker rmi [option] image ... -f 强制删除 制作、推送 在指定路径中找到 Dockerfile 并构建Image, 后面是路径，但路径中必须存在 Dockerfile\ndocker build -t [:namespace]/name:tag Path\n给镜像赋予新的标签, namespace 必须为 dockerid，除非另外购买。\ndocker tag oldname:oldtag namespace/newname:newtag\n将镜像上传至 docker 仓库 DockerHub 上,namespace 必须是用户名,也可以上传至 Gitlab\ndocker push namespace/name:tag\ndocker\n提交修改的镜像\ndocker commit [-a] [-m] CONTAINER [REPOSITORY[:TAG]]\n-a 指明提交者\n-m 提交信息\n在原有镜像的基础上，再叠加上容器的存储层，并构成新的镜像。以后我们运行这个新镜像的时候，就会拥有原有容器最后的文件变化。 此方式更新的镜像有依赖通过 docker save -o dst [REPOSITORY[:TAG]]存盘,删除所有镜像,再通过 docker load -i path 加载新镜像。\nContainer 查看容器 docker ps [-a|-s]\n-a 查看所有容器。\n-s 查看已启动的容器。\n产看容器进程 docker top containerID\n移除容器 可以多个同时删除\ndocker rm container ... [option]\n-f : 强制删除容器。\n-v : 若删除容器则数据卷也删除。\n停止容器 可以同时停止多个\ndocker stop container ...\n启动容器 docker run [:--name] [:-e] [:-v] [:-h] [:--net] [:-p prot0:prot1] [:-d|-i] [:-t] [:--rm] [:--restart] [:--privileged=false] [:--ip] [:--network=] name:tag [:shell]\nrun 命令将会启动 dockerfile 中定义的 CMD 或 ENTRYPOINT 指令。\n--name=xxx 指定容器运行时的名称，可不选，默认为随机字符。\n-p Host0:Host1 表示本地 Host0 映射容器 Host1 端口,若为 -P 则随机映射49000 ~ 49900 端口。\n-d：分离模式: 在后台运行。\n-h：指定主机域名。如 -h domyson.cn。\n-e：为 dockerfile 中的 ENV 的参数变量,设置环境变量，或者覆盖已存在的环境变量 -e TZ=\u0026#34;Asia/Shanghai\u0026#34; 设置时区为上海。\n-u：指定执行用户，一般为 root。\n--rm：停止容器就移除。\n-it: 以交互模式运行容器 (不同于 -d : 以分离模式运行容器),这意味着交互回话 session 结束时,容器就会停止运行，与 -d 互斥。\n-v : 容器内创建一个数据卷。多次重复使用 -v 标记可以创建多个数据卷，也可以挂载一个主机目录作为数据卷 path0:path1(其中path0是主机目录，path1是容器目录)。\n--link container : 连接到其他容器。 这个方法以后将被弃用，推荐使用 --network\n--network NETWORK：指定连接到的网络。\n--ip：指定容器的ip。\n--restart：no、on-failure:n、always 设置容器自动重启模式，若容器已经启动，可以通过 docker update --restart args 来设置参数。\n--privileged：真正给予 Container 中 root 用户 root权限，否则 root 只是一个普通用户。\nshell：指定交互的方式，一般为bash bash -c \u0026#34;cmd string\u0026#34;，这条命令将由启动容器执行。\n查看容器日志 docker logs [opt] CONTAINER\n-f : 跟踪日志输出\n--since :显示某个开始时间的所有日志\n-t : 显示时间戳\n--tail N :仅列出最新N条容器日志\n进入指定容器 docker exec [opt] CONTAINER shell [:args]\n-d ：分离模式: 在后台运行\n-it：以交互模式运行容器 (不同于 -d : 以分离模式运行容器),这意味着交互回话 session 结束时,容器就会停止运行。与 -d 互斥\n-u：指定运行用户,一般设置为 root\n进入容器内部之后，通过 exit 退出\n容器通讯方式 See DockerNetwork\n镜 …","date":1552348800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552348800,"objectID":"8b987a11764fa95fae8b94d2e5213018","permalink":"https://domyson.github.io/post/docker/","publishdate":"2019-03-12T00:00:00Z","relpermalink":"/post/docker/","section":"post","summary":"什么是docker Docker 是一个开源的容器引擎，可以轻松的为任何应用创建一个轻量级的、可移植的、自给自足的容器。开发者和系统管理员在笔记本上编译测试通过的容器可以批量地在生产环境中部署，包括 VMs（虚拟机）、bare metal、OpenStack 集群、云端、数据中心和其他的基础应用平台。容器是完全使用沙箱机制，相互之间不会有任何接口。\n有什么优势 轻量，在一台机器上运行的多个Docker容器可以共享这台机器的操作系统内核；它们能够迅速启动，只需占用很少的计算和内存资源。镜像是通过文件系统层进行构造的，并共享一些公共文件。这样就能尽量降低磁盘用量，并能更快地下载镜像。\n标准，Docker 容器基于开放式标准，能够在所有主流Linux版本、Microsoft Windows以及包括VM、裸机服务器和云在内的任何基础设施上运行。\n安全，Docker 赋予应用的隔离性不仅限于彼此隔离，还独立于底层的基础设施。Docker默认提供最强的隔离，因此应用出现问题，也只是单个容器的问题，而不会波及到整台机器。\n一次发布，到处使用\nDocker和虚拟机 容器和虚拟机具有相似的资源隔离和分配优势，但功能有所不同，因为容器虚拟化的是操作系统，而不是硬件，因此容器更容易移植，效率也更高。\n传统虚拟机技术是虚拟出一套硬件后，在其上运行一个完整操作系统，在该系统上再运行所需应用进程；而容器内的应用进程直接运行于宿主的内核，容器内没有自己的内核，而且也没有进行硬件虚拟。因此容器要比传统虚拟机更为轻便。\n特性 容器 虚拟机 启动 秒级 分钟级 硬盘 MB GB 性能 接近原生 弱于原生 支持量 单机上千 单机几十左右 容器是一个应用层抽象，用于将代码和依赖资源打包在一起。 多个容器可以在同一台机器上运行，共享操作系统内核，但各自作为独立的进程在用户空间中运行 。与虚拟机相比， 容器占用的空间较少（容器镜像大小通常只有几十兆），瞬间就能完成启动。\n虚拟机（VM）是一个物理硬件层抽象，用于将一台服务器变成多台服务器。 管理程序允许多个VM在一台机器上运行。每个VM都包含一整套操作系统、一个或多个应用、必要的二进制文件和库资源，因此占用大量空间。而且VM启动也十分缓慢 。\n虚拟机更擅长于彻底隔离整个运行环境。例如，云服务提供商通常采用虚拟机技术隔离不同的用户。而 Docker 通常用于隔离不同的应用 ，例如前端，后端以及数据库。\nDocker基本组成 镜像 （Image）\n容器（Container）\n仓库（Repository）\n镜像（Image）—— 一个特殊的文件系统 操作系统分为内核和用户空间。对于Linux而言，内核启动后，会挂载root文件系统为其提供用户空间支持。而Docker镜像（Image），就相当于是一个root文件系统。Docker镜像是一个特殊的文件系统，除了提供容器运行时所需的程序、库、资源、配置等文件外，还包含了一些为运行时准备的一些配置参数（如匿名卷、环境变量、用户等）。 镜像不包含任何动态数据，其内容在构建之后也不会被改变。Docker设计时，就充分利用Union FS的技术，将其设计为分层存储的架构。 镜像实际是由多层文件系统联合组成。镜像构建时，会一层层构建，前一层是后一层的基础。每一层构建完就不会再发生改变，后一层上的任何改变只发生在自己这一层。比如，删除前一层文件的操作，实际不是真的删除前一层的文件，而是仅在当前层标记为该文件已删除。在最终容器运行的时候，虽然不会看到这个文件，但是实际上该文件会一直跟随镜像。因此，在构建镜像的时候，需要额外小心，每一层尽量只包含该层需要添加的东西，任何额外的东西应该在该层构建结束前清理掉。分层存储的特征还使得镜像的复用、定制变的更为容易。甚至可以用之前构建好的镜像作为基础层，然后进一步添加新的层，以定制自己所需的内容，构建新的镜像。\n容器（Container）—— 镜像运行时的实体 镜像（Image）和容器（Container）的关系，就像是面向对象程序设计中的类和实例一样，镜像是静态的定义，容器是镜像运行时的实体。容器可以被创建、启动、停止、删除、暂停等 。容器的实质是进程，但与直接在宿主执行的进程不同，容器进程运行于属于自己的独立的命名空间。前面讲过镜像使用的是分层存储，容器也是如此。容器存储层的生存周期和容器一样，容器消亡时，容器存储层也随之消亡。因此，任何保存于容器存储层的信息都会随容器删除而丢失。按照Docker最佳实践的要求，容器不应该向其存储层内写入任何数据 ，容器存储层要保持无状态化。所有的文件写入操作，都应该使用数据卷（Volume）、或者绑定宿主目录，在这些位置的读写会跳过容器存储层，直接对宿主（或网络存储）发生读写，其性能和稳定性更高。数据卷的生存周期独立于容器，容器消亡，数据卷不会消亡。因此， 使用数据卷后，容器可以随意删除、重新run，数据却不会丢失。\n仓库（Repository）—— 集中存放镜像文件的地方 镜像构建完成后，可以很容易的在当前宿主上运行，但是， 如果需要在其它服务器上使用这个镜像，我们就需要一个集中的存储、分发镜像的服务，Docker Registry就是这样的服务。一个Docker Registry中可以包含多个仓库（Repository）；每个仓库可以包含多个标签（Tag）；每个标签对应一个镜像。所以说：镜像仓库是Docker用来集中存放镜像文件的地方类似于我们之前常用的代码仓库。通常，一个仓库会包含同一个软件不同版本的镜像，而标签就常用于对应该软件的各个版本 。我们可以通过\u003c仓库名\u003e:\u003c标签\u003e的格式来指定具体是这个软件哪个版本的镜像。如果不给出标签，将以latest作为默认标签。\nDocker Registry公开服务和私有Docker Registry Docker Registry公开服务是开放给用户使用、允许用户管理镜像的Registry服务。一般这类公开服务允许用户免费上传、下载公开的镜像，并可能提供收费服务供用户管理私有镜像。最常使用的Registry公开服务是官方的Docker Hub ，这也是默认的Registry，并拥有大量的高质量的官方镜像，网址为：hub.docker.com/ 。在国内访问Docker Hub可能会比较慢国内也有一些云服务商提供类似于Docker Hub的公开服务。除了使用公开服务外，用户还可以在本地搭建私有Docker Registry 。Docker官方提供了Docker Registry镜像，可以直接使用做为私有Registry服务。开源的Docker Registry镜像只提供了Docker Registry API的服务端实现，足以支持Docker命令，不影响使用。但不包含图形界面，以及镜像维护、用户管理、访问控制等高级功能。\nImage 查看、拉取、删除 搜索镜像\ndocker search name[:tag]\n拉取镜像,若不指定tag则默认拉取latest\ndocker pull name[:tag]\n查看本地所有镜像\ndocker images\n删除镜像，可以多个删除\ndocker rmi [option] image ... -f 强制删除 制作、推送 在指定路径中找到 Dockerfile 并构建Image, 后面是路径，但路径中必须存在 Dockerfile\ndocker build -t [:namespace]/name:tag Path\n给镜像赋予新的标签, namespace 必须为 dockerid，除非另外购买。\ndocker tag oldname:oldtag namespace/newname:newtag\n将镜像上传至 docker 仓库 DockerHub 上,namespace 必须是用户名,也可以上传至 Gitlab\ndocker push namespace/name:tag\ndocker\n提交修改的镜像\ndocker commit [-a] [-m] CONTAINER [REPOSITORY[:TAG]]\n-a 指明提交者\n-m 提交信息\n在原有镜像的基础上，再叠加上容器的存储层，并构成新的镜像。以后我们运行这个新镜像的时候，就会拥有原有容器最后的文件变化。 此方式更新的镜像有依赖通过 docker save -o dst [REPOSITORY[:TAG]]存盘,删除所有镜像,再通过 docker load -i path 加载新镜像。\nContainer 查看容器 docker ps [-a|-s]\n-a 查看所有容器。\n-s 查看已启动的容器。\n产看容器进程 docker top containerID\n移除容器 可以多个同时删除\ndocker rm container ... [option]\n-f : 强制删除容器。\n-v : 若删除容器则数据卷也删除。\n停止容器 可以同时停止多个\ndocker stop container ...\n启动容器 docker run [:--name] [:-e] [:-v] [:-h] [:--net] [:-p prot0:prot1] [:-d|-i] [:-t] [:--rm] [:--restart] [:--privileged=false] [:--ip] [:--network=] name:tag [:shell]\nrun 命令将会启动 dockerfile 中定义的 CMD 或 ENTRYPOINT 指令。\n--name=xxx 指定容器运行时的名称，可不选，默认为随机字符。\n-p Host0:Host1 表示本地 Host0 映射容器 Host1 端口,若为 -P 则随机映射49000 ~ 49900 端口。\n-d：分离模式: 在后台运行。\n-h：指定主机域名。如 -h domyson.cn。\n-e：为 dockerfile 中的 ENV 的参数变量,设置环境变量，或者覆盖已存在的环境变量 -e TZ=\"Asia/Shanghai\" 设置时区为上海。\n-u：指定执行用户，一般为 root。\n--rm：停止容器就移除。\n-it: 以交互模式运行容器 (不同于 -d : 以分离模式运行容器),这意味着交互回话 session 结束时,容器就会停止运行，与 -d 互斥。\n-v : 容器内创建一个数据卷。多次重复使用 -v 标记可以创建多个数据卷，也可以挂载一个主机目录作为数据卷 path0:path1(其中path0是主机目录，path1是容器目录)。\n--link container : 连接到其他容器。 这个方法以后将被弃用，推荐使用 --network\n--network NETWORK：指定连接到的网络。\n--ip：指定容器的ip。\n--restart：no、on-failure:n、always 设置容器自动重启模式，若容器已经启动，可以通过 docker update --restart args 来设置参数。\n--privileged：真正给予 Container 中 root 用户 root权限，否则 root 只是一个普通用户。\nshell：指定交互的方式，一般为bash bash -c \"cmd string\"，这条命令将由启动容器执行。\n查看容器日志 docker logs [opt] CONTAINER\n-f : 跟踪日志输出\n--since :显示某个开始时间的所有日志\n-t : 显示时间戳\n--tail N :仅列出最新N条容器日志\n进入指定容器 docker exec [opt] CONTAINER shell [:args]\n-d ：分离模式: 在后台运行\n-it：以交互模式运行容器 (不同于 -d : 以分离模式运行容器),这意味着交互回话 session 结束时,容器就会停止运行。与 -d 互斥\n-u：指定运行用户,一般设置为 root\n进入容器内部之后，通过 exit 退出\n容器通讯方式 See DockerNetwork\n镜像体积优化 Docker 由多个 Layers 组成（上限是127层）。而 Dockerfile 每一条指令都会创建一层 Layers。\n优化基础镜像 使用 Alpine 基础镜像\nAlpine是一个高度精简又包含了基本工具的轻量级Linux发行版，基础镜像仅 4.41MB\n使用 scratch 基础镜像\nscratch是一个空镜像，只能用于构建其他镜像\n使用 busybox 基础镜像\n如果希望镜像里可以包含一些常用的Linux工具，busybox镜像是个不错选择，镜像本身只有1.16M，非常便于构建小镜像。\n串联 Dockerfile 指令 通过 \u0026\u0026 和 \\ 将多个 Run 命令合并成一个\n多段构建 待完善\nDocker数据卷 数据卷可以在容器之间共享和重用 对数据卷的修改会立马生效 对数据卷的更新，不会影响镜像 数据卷默认会一直存在，即使容器被删除 创建数据卷 在 run 命令中 -v /data 标记来创建一个数据卷并挂载到容器里。在一次 run 中多次使用可以挂载多个数据卷。(创建一个容器，并加载一个数据卷到容器的 /data 目录) 也可以在 Dockerfile 中使用 VOLUME 来添加一个或者多个新的卷到由该镜像创建的任意容器。 删除数据卷 数据卷是被设计用来持久化数据的，它的生命周期独立于容器，Docker不会在容器被删除后自动删除数据卷，并且也不存在垃圾回收这样的机制来处理没有任何容器引用的数据卷。如果需要在删除容器的同时移除数据卷。可以在删除容器的时候使用 docker rm -v 这个命令。无主的数据卷可能会占据很多空间，要清理会很麻烦。 挂载一个主机目录作为数据卷 docker run -d -P --name web -v /src/webapp:/opt/webapp[:权限] 上面的命令加载主机的 /src/webapp 目录到容器的 /opt/webapp 目录，默认权限是读写，也可以指定为只读(ro) --volumes-from 在run的时候指定数据卷容器 查看数据卷的信息\ndocker inspect contianerID\n查看所有数据卷\ndocker volume ls\n清除所有无主数据卷\ndocker volume prune\nDocker权限验证 版本\ndocker version\n登陆\ndocker login\n登出\ndocker logout\nDocker远程访问 Docker-Compose Docker-Compose （docker编排）是 docker 提供的一个命令行工具，用来定义和运行由多个容器组成的应用。可以通过 docker-compose.yml 文件声明式的定义应用程序的各个服务，并由单个命令完成应用的创建和启动。\n官方文档\nDocker-Compose将所管理的容器分为三层，分别是工程（project），服务（service）以及容器（container）。Docker-Compose运行目录下的所有文件（docker-compose.yml，extends文件或环境变量文件等）组成一个工程，若无特殊指定工程名即为当前目录名。一个工程当中可包含多个服务，每个服务中定义了容器运行的镜像，参数，依赖。一个服务当中可包括多个容器实例，Docker-Compose并没有解决负载均衡的问题，因此需要借助其它工具实现服务发现及负载均衡。\n","tags":["docker"],"title":"Docker","type":"post"},{"authors":null,"categories":["others"],"content":"简介 Nginx功能丰富，可作为HTTP服务器，也可作为反向代理服务器，邮件服务器。支持FastCGI、SSL、Virtual Host、URL Rewrite、Gzip等功能。并且支持很多第三方的模块扩展。\nNginx下载\n常用功能 负载均衡\n反向代理\n正向代理\n文件服务器\nNginx命令 nginx -s [reload|start|stop|quit] 向nginx发送一个信号\nnginx -c path 指定nginx启动配置，linux 默认在 /etc/nginx/nginx.conf 下\nnginx -g \u0026#34;daemon off;\u0026#34; 不以守护进程的方式启动，这点在 docker 中特别重要，默认是以守护进程的方式启动\nNginx正向代理 server { # 配置DNS解析IP地址，比如 Google Public DNS，以及超时时间（5秒） resolver 8.8.8.8; # 必需 resolver_timeout 5s; # 监听端口 listen 8080; access_log /home/reistlin/logs/proxy.access.log; error_log /home/reistlin/logs/proxy.error.log; location / { # 配置正向代理参数 proxy_pass $scheme://$host$request_uri; # 解决如果URL中带\u0026#34;.\u0026#34;后Nginx 503错误 proxy_set_header Host $http_host; # 配置缓存大小 proxy_buffers 256 4k; # 关闭磁盘缓存读写减少I/O proxy_max_temp_file_size 0; # 代理连接超时时间 proxy_connect_timeout 30; # 配置代理服务器HTTP状态缓存时间 proxy_cache_valid 200 302 10m; proxy_cache_valid 301 1h; proxy_cache_valid any 1m; } } 添加环境变量 http_proxy=http://192.168.1.9:8080 unix系统需要重新 source /etc/profile 来应用环境变量\nNginx文件服务器 #增加一个 server 模块 server{ listen 8080; server_name 8.8.8.8; charset utf-8; #设置编码，防止乱码 #root /usr/share/nginx/html; root /data/; location / { autoindex on; #显示目录 autoindex_exact_size on; #显示文件大小 autoindex_localtime on; #显示文件时间 auth_basic \u0026#34;treasure\u0026#34;; #密码提示短语 auth_basic_user_file /blog/nginx/htpasswd; #认证密码访问路径 } error_page 404 /40x.html; location = /40x.html { } } nginx.conf #user nobody; #运行用户，可不设置 worker_processes 1; #工作进程，一般为cpu荷属 #error_log logs/error.log; #日志文件路径，后面是日志等级 #error_log logs/error.log notice; #error_log logs/error.log info; #pid logs/nginx.pid; #进程pid文件路径 events { use epoll; #epoll是多路I/O复用，可极大提高性能，select,poll,kqueue accept_mutex on; # 连接互斥，防止惊群现象 multi-accept on; # 进程接收多个连接 worker_connections 1024; #单个worker最大的并发数 } http { include mime.types; #文件拓展名映射表 default_type application/octet-stream; #默认文件类型 log_format format \u0026#39;$remote_addr - $remote_user [$time_local] \u0026#34;$request\u0026#34; \u0026#39; \u0026#39;$status $body_bytes_sent \u0026#34;$http_referer\u0026#34; \u0026#39; \u0026#39;\u0026#34;$http_user_agent\u0026#34; \u0026#34;$http_x_forwarded_for\u0026#34;\u0026#39;; #日志格式 #access_log logs/access.log format; sendfile on; # 允许sendfile方式传输文件，默认为off，可以在http块，server块，location块 sendfile_max_chunk 100k; #每个进程每次调用传输数量不能大于设定的值，默认为0，即不设上限 #tcp_nopush on; # 默认关闭，关闭 nagle 算法，同 sendfile 一起使用 #tcp_nodelay on; # 与 tcp_nopush互斥 keepalive_timeout 65; # 连接超时时间，单位s #----------------- gzip --------------------# #gzip on; #开启 gzip压缩功能 #gzip_min_length 1k; #允许最小压缩字节数，建议大于1k #gzip_buffers 4 32k; #分配4块大小为32k的缓冲块 #gzip_http_version 1.0; #gzip版本 #gzip_comp_level 8; #压缩等级 0~9 #gzip_types text/plain application/x-javascropt text/css application/xml #使用gzip压缩的类型 #gzip_vary on; error_page 404 http://xxxxx.yyy; # http全局错误页 upstream serverName{ server 8.8.8.8:80 weight=1 max_fails=2 fail_timeout=30s; server 0.0.0.0:81 backup; #热备 #若只有一个负载服务器，则不能设置权重，最大失败数为2，超过则认为主机不可用， #30s表示两次连接失败的超时时间间隔 # ll+weight：轮询加权算法，默认 # ip_hash: 哈希算法，可能使部分服务器负载变大 # least_conn: 最少链接，优先分配 # least_time: 相应最快的权重越大 } server { listen 80; #监听端口 server_name localhost; #监听地址或域名 #root #此server块全局资源路径 #index index.html index.htm #此server块全局索引界面,首页排序 #charset koi8-r; #access_log logs/host.access.log main; #error_page 404 405 /40x.html #error_page 500 502 503 504 /50x.html #server全局错误页面定向到location location / { root html; index index.html index.htm; error_page 404 405 /50x.html #错误页面定向到其他 location } location /proxy/ { proxy_pass http://1.1.1.1:80/proxy/; #代理网址 proxy_set_header Host $host; #代理网站域名 proxy_set_header X-Real-IP $remote_addr; #远程地址 proxy_set_header X-Forwarded-For $proxy_add-x_forwarder_for; # #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache\u0026#39;s document root # concurs with nginx\u0026#39;s one # #location ~ /\\.ht { # deny all; #} #location ~.*\\.(js|css)?$ { #expires 30d; #客户端缓存js,css 30天 #access_log off; #关闭日志 #} #location /resources/ { #deny all; #禁止所有ip访问 #allow 4.4.4.4; #aloow 5.5.5.5; #允许访问的ip #} } # another virtual host using mix of IP-, name-, and port-based configuration # #server { # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / { # root html; # index index.html index.htm; # } #} # HTTPS server # #server { # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / { # root html; # index index.html index.htm; # } #} } 路径匹配规则 访问 http://treasure.com/abc/index.html\nlocation /abc/ { proxy_pass http://treasure.com/; # 有 / 后缀会被location 截断 # …","date":1552089600,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1552089600,"objectID":"8aba5719cea20c5f2194ee6cdfc5691d","permalink":"https://domyson.github.io/post/nginx/","publishdate":"2019-03-09T00:00:00Z","relpermalink":"/post/nginx/","section":"post","summary":"简介 Nginx功能丰富，可作为HTTP服务器，也可作为反向代理服务器，邮件服务器。支持FastCGI、SSL、Virtual Host、URL Rewrite、Gzip等功能。并且支持很多第三方的模块扩展。\nNginx下载\n常用功能 负载均衡\n反向代理\n正向代理\n文件服务器\n","tags":null,"title":"Nginx","type":"post"},{"authors":null,"categories":["others"],"content":"Link\nMarkdown语法 目录 只能跳转标题，如果有同名标题与标题等级无关，匹配最优先的标题\n标题 字体 引用 分割线 超链接 表格 代码 流程图 语法高亮 转义字符 一、标题 在想要设置为标题的文字前面加#来表示。一个#是一级标题，二个#是二级标题，以此类推。支持六级标题。\n示例:\n# 这是一级标题 ## 这是二级标题 ### 这是三级标题 #### 这是四级标题 ##### 这是五级标题 ###### 这是六级标题 效果:\n这是一级标题 这是二级标题 这是三级标题 这是四级标题 这是五级标题 这是六级标题 二、字体 加粗 要加粗的文字左右分别用两个*号包起来\n斜体 要倾斜的文字左右分别用一个*号包起来\n斜体加粗 要倾斜和加粗的文字左右分别用三个*号包起来\n删除线 要加删除线的文字左右分别用两个~~号包起来\n示例:\n**这是加粗的文字** *这是倾斜的文字* ***这是斜体加粗的文字*** ~~这是加删除线的文字~~ 效果:\n这是加粗的文字\n这是倾斜的文字`\n这是斜体加粗的文字\n这是加删除线的文字\n三、引用 在引用的文字前加\u0026gt;即可。引用也可以嵌套，如加两个»三个»\u0026gt; n个…\n示例:\n\u0026gt;这是引用的内容 \u0026gt;\u0026gt;这是引用的内容 \u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;\u0026gt;这是引用的内容 效果:\n这是引用的内容\n这是引用的内容\n这是引用的内容\n四、分割线 三个或者三个以上的 - 或者 * 都可以。\n示例:\n--- ---- *** ***** 效果:\n五、图片 语法:\n![alt](图片地址 \u0026#34;title\u0026#34;) alt 就是显示在图片下面的文字，相当于对图片内容的解释。title 是图片的标题，当鼠标移到图片上时显示的内容。title 可加可不加\n效果:\n六、超链接 语法：\n[name](url \u0026#34;title\u0026#34;) `title` 可加可不加 示例:\n[简书](http://jianshu.com) [百度](http://baidu.com) 效果:\n简书\n百度\n七、列表 无序列表 语法：\n无序列表用 - + * 任何一种都可以\n- 列表内容 + 列表内容 * 列表内容 注意：- + * 跟内容之间都要有一个空格\n效果：\n列表内容 列表内容 列表内容 列表内容 有序列表 语法:\n1. 列表内容 2. 列表内容 3. 列表内容 注意：序号跟内容之间要有空格\n效果:\n列表内容 列表内容 列表内容 列表嵌套 示例:\n+ 一级无序列表内容 + 二级无序列表内容 + 二级无序列表内容 + 二级无序列表内容 + 一级无序列表内容 1. 二级有序列表内容 2. 二级有序列表内容 3. 二级有序列表内容 1. 一级有序列表内容 + 二级无序列表内容 + 二级无序列表内容 + 二级无序列表内容 2. 一级有序列表内容 1. 二级有序列表内容 2. 二级有序列表内容 3. 二级有序列表内容 效果:\n一级无序列表内容\n二级无序列表内容 二级无序列表内容 二级无序列表内容 一级无序列表内容\n二级有序列表内容 二级有序列表内容 二级有序列表内容 一级有序列表内容\n二级无序列表内容 二级无序列表内容 二级无序列表内容 一级有序列表内容\n二级有序列表内容 二级有序列表内容 二级有序列表内容 八、表格 语法:\n表头|表头|表头 ---|:--:|---: 内容|内容|内容 内容|内容|内容 第二行分割表头和内容。- 有一个就行，为了对齐，多加了几个文字默认居左,- 两边加：表示文字居中,- 右边加：表示文字居右\n注：原生的语法两边都要用 | 包起来。此处省略\n示例:\n姓名|技能|排行 --|:--:|--: 刘备|哭|大哥 关羽|打|二哥 张飞|骂|三弟 效果:\n姓名 技能 排行 刘备 哭 大哥 关羽 打 二哥 张飞 骂 三弟 九、代码 语法:\n单行代码:代码之间分别用一个反引号包起来 `代码内容`,\n代码块:代码之间分别用三个反引号包起来，且两边的反引号单独占一行\n示例:\n单行代码\n`create database hero;` 代码块\n``` function fun(){ echo \u0026#34;这是一句非常牛逼的代码\u0026#34;; } fun(); ``` 效果:\n单行代码\ncreate database hero;\n代码块\nfunction fun(){ echo \u0026#34;这是一句非常牛逼的代码\u0026#34;; } fun(); 十、流程图 Vscode 不支持\n```flow st=\u0026gt;start: 开始 op=\u0026gt;operation: My Operation cond=\u0026gt;condition: Yes or No? e=\u0026gt;end st-\u0026gt;op-\u0026gt;cond cond(yes)-\u0026gt;e cond(no)-\u0026gt;op \u0026amp;``` 十一、语法高亮 语法:\n```key code ``` 支持的 key 常用\nlanguage key C++ cpp C# cs CSS css Erlang erlang Go go HTML html JavaScript javascript Json json Lua lua Makefile makefile Nginx nginx Python python ProtocolBuffer protobuf SQL sql text text/plain TypeScript typescript XML xml 十二、转义字符 显示结果 描述 实体名称 实体编号 空格 \u0026amp;nbsp; \u0026amp;#160; \u0026lt; 小于号 \u0026amp;lt; \u0026amp;#60; \u0026gt; 大于号 \u0026amp;gt; \u0026amp;#62; \u0026amp; 与号 \u0026amp;amp; \u0026amp;#38; \u0026#34; 引号 \u0026amp;quot; \u0026amp;#34; \u0026#39; 撇号 \u0026amp;apos;(IE不支持) \u0026amp;#39; 十三、公式 $$dmg=atk-def$$\n","date":1551744000,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551744000,"objectID":"7a2935dbc30bcdd260a376f839e6bc50","permalink":"https://domyson.github.io/post/markdown/","publishdate":"2019-03-05T00:00:00Z","relpermalink":"/post/markdown/","section":"post","summary":"Link\nMarkdown语法 目录 只能跳转标题，如果有同名标题与标题等级无关，匹配最优先的标题\n标题 字体 引用 分割线 超链接 表格 代码 流程图 语法高亮 转义字符 ","tags":["Markdown"],"title":"Markdown","type":"post"},{"authors":null,"categories":["linux"],"content":"前言 数据的读取分为:\n等待数据准备\n等待内核拷贝至用户空间\n基本模型矩阵\n阻塞 非阻塞 同步 Read/Write Read\\Write(O_NONBLOCK) 异步 I/O multiplexing(select/poll) AIO 同步阻塞I/O 此时用户阻塞等待内核完成。\n同步非阻塞I/O 此时用户进程每过一段时间询问内核操作是否完成，若完成则开始复制，感官上用户进程没有阻塞，可以称之为伪异步，但本质还是同步。\nI/O多路复用 I/O复用 有时又被称为 事件驱动I/O, 它的最大优势在于，我们可以将感兴趣的多个I/O事件（更精确的说，应该是 I/O 所对应的文件描述符）注册到 select/poll/epoll/kqueue 之中某一个系统调用上（很多时候，这些系统调用又被称为多路复用器。假设此时我们选择了 select() ）。此后，调用进程会阻塞在 select() 系统调用之上（而不是阻塞在真正的 I/O 系统调用（如 read(), write() 等）上）。select() 会负责监视所有已注册的 I/O 事件，一旦有任意一个事件的数据准备好，那么 select() 会立即返回，此时我们的用户进程便能够进行数据的复制操作。\nselect、poll、epoll、kqueue。\nselect\n说的通俗一点就是各个客户端连接的文件描述符也就是套接字，都被放到了一个集合中，调用 select 函数之后会一直监视这些文件描述符中有哪些可读，如果有可读的描述符那么我们的工作进程就去读取资源，仅返回触发事件，不返回事件id，最多只能监测1024个连接，线程不安全\npoll\npoll 和 select 的实现非常类似，本质上的区别就是存放 fd 集合的数据结构不一样。select 在一个进程内可以维持最多 1024 个连接，poll 在此基础上做了加强，可以维持任意数量的连接。\nepoll\nepoll 是基于内核的反射机制，在有活跃的 socket 时，系统会调用我们提前设置的回调函数。而 poll 和 select 都是遍历。在大多数客户端都很活跃的情况下，系统会把所有的回调函数都唤醒，所以会导致负载较高。既然要处理这么多的连接，那倒不如 select 遍历简单有效。\n信号驱动I/O 在这种模型下，我们首先开启套接字的信号驱动式I/O功能，并通过sigaction系统调用安装一个信号处理函数。该系统调用将立即返回，我们的进程继续工作，也就是说他没有被阻塞。当数据报准备好读取时，内核就为该进程产生一个SIGIO信号。我们随后就可以在信号处理函数中调用read读取数据报，并通知主循环数据已经准备好待处理，也可以立即通知主循环，让它读取数据报。此时在收到内核完成信号之前是非阻塞的，但是内核复制数据时会发生阻塞，所以此模型也是一个伪异步。\n异步非阻塞I/O Windows的IOCP模型\n异步非阻塞 /O模型 是一种处理与 I/O 重叠进行的模型。读请求会立即返回，说明 read 请求已经成功发起了。在后台完成读操作时，应用程序然后会执行其他处理操作。当 read 的响应到达时，就会产生一个信号或执行一个基于线程的回调函数来完成这次 I/O 处理过程。本质上阻塞是用户 I/O 线程，主线程是非阻塞的，所以此模型是真异步。\n仅unix支持\n几种I/O模型的比较 判断是否是真正异步的方式是，内核完成通知之后是否是主线程处理，还是I/O线程处理。\nReactor和Proactor 还没写\n","date":1551052800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1551052800,"objectID":"b2baa70525b7d4592bbd2ea22f6ba333","permalink":"https://domyson.github.io/post/linux/io/","publishdate":"2019-02-25T00:00:00Z","relpermalink":"/post/linux/io/","section":"post","summary":"前言 数据的读取分为:\n等待数据准备\n等待内核拷贝至用户空间\n基本模型矩阵\n阻塞 非阻塞 同步 Read/Write Read\\Write(O_NONBLOCK) 异步 I/O multiplexing(select/poll) AIO ","tags":["I/O"],"title":"I/O","type":"post"},{"authors":null,"categories":null,"content":"Liunx 文件系统 对于 drwxr-xr-x 4 root root 4096 Nov 28 00:00 hook\n文件类型 符号 描述 d 目录 l 符号链接 s 套接字文件 b 块设备文件 c 字符设备文件 p 命名管道文件 - 普通文件，不属于上述任意一种 权限更换 chmod [who] operator [permission] filename\nwho\n符号 描述 u 文件属主权限 g 同组用户权限 o 其他用户权限 a 所有用户 operator\n符号 描述 + 增加权限 - 取消权限 = 设定权限 permission\n符号 描述 r 读权限 w 写权限 x 执行权限 ","date":-62135596800,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":-62135596800,"objectID":"f521c6a521e3ebd4688ef457d568fd1a","permalink":"https://domyson.github.io/post/linux/file/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/post/linux/file/","section":"post","summary":"Liunx 文件系统 对于 drwxr-xr-x 4 root root 4096 Nov 28 00:00 hook\n文件类型 符号 描述 d 目录 l 符号链接 s 套接字文件 b 块设备文件 c 字符设备文件 p 命名管道文件 - 普通文件，不属于上述任意一种 权限更换 chmod [who] operator [permission] filename\nwho\n符号 描述 u 文件属主权限 g 同组用户权限 o 其他用户权限 a 所有用户 operator\n符号 描述 + 增加权限 - 取消权限 = 设定权限 permission\n符号 描述 r 读权限 w 写权限 x 执行权限 ","tags":null,"title":"","type":"post"}]