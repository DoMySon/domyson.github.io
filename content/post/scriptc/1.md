---
title: lex
date: 2023-10-04
tags: ['']
categories: ['scriptc']
description: 
toc: true
draft: false
---


# 序

对于一个源码文件而言，里面的内容只是一个个字符，机器是无法识别的，而词法分析器的作用类似于转义器，将一个个字符拆成若干个有特定意义的词，而这一过程称为词法分析，此时它也不能被机器(或者这个虚拟机)识别



# 词法分析器


## Token,Keyword,界符，常数，运算符

`token` 以及 `keyword`是存在区别的，像`token` 可以是认为是一个此的描述，如:

```c
    const int sum = 100; 

    typedef struct my_struct{
        int a ;

        unsigned int b;

        char *c;
    };
```

> 学过语言的都知道，什么是语言关键字。


`typedef`,`struct`,`int`,`my_struct` 等都可以认为是一个`token`,可以简单理解为一个词的代号，而`keyword`属于被包含关系，`typedef`,`struct`,`int` 它们属于`keyword`,因为它们是程序内部定义"词"，而`my_struct`则属于用于定义的，

像类似于 `+,-,*,/` 等都属于运算符

其中 `const int sum = 100; ` 中的`100` 则认为是一个常数.



## 基本设计

1. 首先我们为一个词定义一些`token`,如

```c
typedef enum Token {
    EOF = 0,
    COMMENT,
    IDENT,

    __KEYWORD_BEGIN
    IF,
    ELSE,
    SWITCH,
    CASE,
    RETURN,
    // etc...
    __KEYWORD_END,

    __MATH_BEGIN
    Add,          // +
	Sub,          // -
	Mul,          // *
	Quo,          // /
	Rem,          // %
	And,          // &
	Or,           // |
    __MATH_END
};
```

可以属于到几个特殊的定义 `__XXX_BEING,__XXX_END` 这是为了方便后续快速区分这些"词"是属于那些种类


2. 其次我们需要定义一个辅助函数，如上所述 `const int sum = 100`; 而这`100`解析出来应该是个数字而不是一个字符串

    ```c
    bool is_dight(char c){
        return '0'<=c && c <='9';
    }
    ```

    这一步只处理了一个字符，而后续只需要一直扫描直到不能满足条件为止，如出现一个字母，那么可以认为语法错误，扫描到`;`则认为是结束了

    ```c
    bool is_letter(char c) {
        return ('a' <=c && c <='z') || ('A' <=c && c <='Z');
    }
    ```

    这个函数专门处理一些关键字，和`identity`

    > 辅助函数只能处理当前字符，那么如何知道是否满足某个条件，如变量只允许下划线和字母开头，答案就是状态机，类似于一个临时缓冲，将扫描到的字符放入其中方便做检测，而实际开发中其实只需要记录两次偏移的位置就可以拿到这段字符了


## 分析器的分析流程

分析器其实就是按照一个个遍历的方式将这串文本拆成一个个的`token`的过程

```c
typedef struct lex {

    unsigned int size; // sizeof the buf length

    unsigned int offset; // current read offset

    unsigned int line;

    char buf[];
};


typedef struct token{
    Token __token;

    unsigned int line;
};


int lex_next(lex *l,token *tk){
    while(l->offset < l ->size){
        // lex_skipwhitespace()
        switch (l->buf[l->offset]){
            case '/':
                if (l->buf[l->offset +1] == '/'){
                    // lex_skipcomment()
                    tk->__token = COMMENT;
                }else{
                    // maybe is math div
                }
                break
            // etc ... switch
        }
    }
}
```

至此，词法分析器的大致原理已经分析完毕了，后续可以参考 `AST` 以及 语法分析器`Grammar`

{{< adsense-footer>}}
